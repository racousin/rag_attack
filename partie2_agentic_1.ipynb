{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapitre 0: Comprendre les Outils et l'Appel de Fonctions\n",
    "\n",
    "Avant de plonger dans les syst√®mes agentiques avanc√©s, nous devons comprendre un concept fondamental : **comment les LLMs utilisent les outils**.\n",
    "\n",
    "## Qu'est-ce qu'un Outil ?\n",
    "\n",
    "Les outils (aussi appel√©s \"function calling\") permettent aux LLMs de :\n",
    "- Effectuer des calculs\n",
    "- Interroger des bases de donn√©es\n",
    "- Appeler des APIs externes\n",
    "- Acc√©der √† des informations en temps r√©el\n",
    "\n",
    "**Concept cl√©** : Les LLMs n'ex√©cutent pas directement les outils. Ils **g√©n√®rent des instructions structur√©es** qui nous indiquent quel outil appeler et avec quels param√®tres. Nous ex√©cutons ensuite l'outil et renvoyons le r√©sultat au LLM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from openai import AzureOpenAI\n",
    "import os\n",
    "\n",
    "# Configuration Azure OpenAI\n",
    "config = {\n",
    "    \"openai_endpoint\": \"\",\n",
    "    \"openai_key\": \"\",\n",
    "    \"chat_deployment\": \"\"\n",
    "}\n",
    "\n",
    "# Initialiser le client Azure OpenAI\n",
    "client = AzureOpenAI(\n",
    "    api_key=config[\"openai_key\"],\n",
    "    api_version=\"2024-02-01\",\n",
    "    azure_endpoint=config[\"openai_endpoint\"]\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Client Azure OpenAI initialis√©\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exemple d'Outil : Calculatrice Simple\n",
    "\n",
    "Cr√©ons notre premier outil : une calculatrice simple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculatrice(operation: str, a: float, b: float) -> float:\n",
    "    \"\"\"Une calculatrice simple qui effectue des op√©rations de base.\"\"\"\n",
    "    if operation == \"additionner\":\n",
    "        return a + b\n",
    "    elif operation == \"soustraire\":\n",
    "        return a - b\n",
    "    elif operation == \"multiplier\":\n",
    "        return a * b\n",
    "    elif operation == \"diviser\":\n",
    "        if b == 0:\n",
    "            return \"Erreur : Division par z√©ro\"\n",
    "        return a / b\n",
    "    else:\n",
    "        return f\"Erreur : Op√©ration inconnue '{operation}'\"\n",
    "\n",
    "# Testons-la\n",
    "print(calculatrice(\"multiplier\", 25, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"multiplie 9712439 et -138213\" # Bonne r√©ponse: -1342385331507\n",
    "response = client.chat.completions.create(\n",
    "    model=config[\"chat_deployment\"],\n",
    "    messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    ")\n",
    "\n",
    "print(\"\\nR√âPONSE DU LLM (texte brut) :\")\n",
    "print(\"=\" * 80)\n",
    "reponse_texte = response.choices[0].message.content\n",
    "print(reponse_texte)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Questions :**\n",
    "1. Pourquoi utiliser un outil de calculatrice ? Le r√©ponse est-elle correcte? Essayer plusieurs fois.\n",
    "2. Quelles id√©es avez-vous pour que le llm puisse utiliser la calculatrice?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approche manuelle: a. Prompter avec des outils\n",
    "\n",
    "Construisons nous-m√™mes le prompt qui d√©crit les outils disponibles :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construisons manuellement le prompt qui d√©crit l'outil\n",
    "\n",
    "description_outil = \"\"\"**calculatrice** : Effectue des op√©rations arithm√©tiques de base\n",
    "Param√®tres :\n",
    "- operation (string) : doit √™tre \"additionner\", \"soustraire\", \"multiplier\", ou \"diviser\"\n",
    "- a (number) : le premier nombre\n",
    "- b (number) : le deuxi√®me nombre\n",
    "\n",
    "Pour utiliser un outil, tu DOIS r√©pondre avec CE FORMAT JSON EXACT (rien d'autre) :\n",
    "```json\n",
    "{\n",
    "  \"outil\": \"calculatrice\",\n",
    "  \"arguments\": {\n",
    "    \"operation\": \"multiplier\",\n",
    "    \"a\": 25,\n",
    "    \"b\": 4\n",
    "  }\n",
    "}\n",
    "```\"\"\"\n",
    "\n",
    "message_utilisateur = \"\"\"Combien font 9712439 multipli√© par -138213 ?\"\"\"\n",
    "\n",
    "prompt = f\"\"\"Tu es un assistant qui a acc√®s √† des outils. Voici les outils disponibles :\n",
    "\n",
    "{description_outil}\n",
    "\n",
    "Si tu n'as pas besoin d'utiliser un outil, r√©ponds normalement en texte.\n",
    "\n",
    "Question de l'utilisateur : {message_utilisateur} \"\"\"\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"PROMPT COMPLET ENVOY√â AU LLM :\")\n",
    "print(\"=\" * 80)\n",
    "print(prompt)\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Appeler le LLM\n",
    "response = client.chat.completions.create(\n",
    "    model=config[\"chat_deployment\"],\n",
    "    messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    ")\n",
    "\n",
    "print(\"\\nR√âPONSE DU LLM (texte brut) :\")\n",
    "print(\"=\" * 80)\n",
    "reponse_texte_1 = response.choices[0].message.content\n",
    "print(reponse_texte_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Questions :**\n",
    "1. Le LLM a t-il compris la consigne? Essayer d'autres questions ci-dessous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "message_utilisateur = \"\"\"Essayer d'autres questions?\"\"\"\n",
    "\n",
    "prompt = f\"\"\"Tu es un assistant qui a acc√®s √† des outils. Voici les outils disponibles :\n",
    "\n",
    "{description_outil}\n",
    "\n",
    "Si tu n'as pas besoin d'utiliser un outil, r√©ponds normalement en texte.\n",
    "\n",
    "Question de l'utilisateur : {message_utilisateur} \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=config[\"chat_deployment\"],\n",
    "    messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    ")\n",
    "\n",
    "print(\"\\nR√âPONSE DU LLM (texte brut) :\")\n",
    "print(\"=\" * 80)\n",
    "reponse_texte = response.choices[0].message.content\n",
    "print(reponse_texte)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approche manuelle: b. Parser le json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maintenant, on doit PARSER manuellement cette r√©ponse\n",
    "print(\"\\nüìù PARSING MANUEL DE LA R√âPONSE :\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Le LLM a retourn√© du texte, on doit extraire le JSON\n",
    "import re\n",
    "\n",
    "try:\n",
    "    # Chercher le JSON dans la r√©ponse (souvent entre ```json et ```)\n",
    "    json_match = re.search(r'```json\\s*(\\{.*?\\})\\s*```', reponse_texte_1, re.DOTALL)\n",
    "    \n",
    "    if json_match:\n",
    "        json_str = json_match.group(1)\n",
    "    else:\n",
    "        # Peut-√™tre que c'est du JSON direct\n",
    "        json_str = reponse_texte.strip()\n",
    "    \n",
    "    # Parser le JSON\n",
    "    appel_outil_parsed = json.loads(json_str)\n",
    "    \n",
    "    print(\"‚úÖ JSON pars√© avec succ√®s !\")\n",
    "    print(json.dumps(appel_outil_parsed, indent=2, ensure_ascii=False))\n",
    "    \n",
    "    # Extraire les informations\n",
    "    nom_outil = appel_outil_parsed.get(\"outil\")\n",
    "    arguments = appel_outil_parsed.get(\"arguments\")\n",
    "    \n",
    "    print(f\"\\nüîß Outil √† appeler : {nom_outil}\")\n",
    "    print(f\"üìã Arguments : {arguments}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Erreur lors du parsing : {e}\")\n",
    "    print(f\"‚ö†Ô∏è  Probl√®me : Le LLM n'a pas retourn√© le format attendu !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Questions :**\n",
    "1. Le parser arrive-t-il a parser/interpreter le texte?\n",
    "2. Pourquoi utiliser le format json?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approche manuelle: c. Executer l'outil avec les arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bonne r√©ponse: -1342385331507\n",
    "# Ex√©cuter l'outil\n",
    "if nom_outil == \"calculatrice\":\n",
    "    resultat = calculatrice(**arguments)\n",
    "    print(f\"‚úÖ R√©sultat : {resultat}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Questions :**\n",
    "1. La reponse est-elle correcte?\n",
    "2. Est-ce que vous voyez comment ajouter d'autres outils?\n",
    "3. Quelles sont les risques et"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approche g√©n√©raliste:\n",
    "En pratiques les outils peuvent etre compliqu√©s et en nombre assez important. La plupart des API de LLM integrent une notion d'outils afin de faciliter les interactions avec ceux-ci (int√©gration des descriptions au prompt, parsing des r√©sultats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Description de l'Outil - Permet au LLM d'Utiliser Votre Outil\n",
    "\n",
    "Le LLM a besoin de savoir :\n",
    "1. Ce que fait l'outil\n",
    "2. Quels param√®tres il attend\n",
    "3. Le type et format de chaque param√®tre\n",
    "\n",
    "Cela se fait via un **sch√©ma d'outil** :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outil_calculatrice = {\n",
    "    \"type\": \"function\",\n",
    "    \"function\": {\n",
    "        \"name\": \"calculatrice\",\n",
    "        \"description\": \"Effectue des op√©rations arithm√©tiques de base (additionner, soustraire, multiplier, diviser) sur deux nombres.\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"operation\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"enum\": [\"additionner\", \"soustraire\", \"multiplier\", \"diviser\"],\n",
    "                    \"description\": \"L'op√©ration arithm√©tique √† effectuer\"\n",
    "                },\n",
    "                \"a\": {\n",
    "                    \"type\": \"number\",\n",
    "                    \"description\": \"Le premier nombre\"\n",
    "                },\n",
    "                \"b\": {\n",
    "                    \"type\": \"number\",\n",
    "                    \"description\": \"Le deuxi√®me nombre\"\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"operation\", \"a\", \"b\"]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"Sch√©ma de l'outil :\")\n",
    "print(json.dumps(outil_calculatrice, indent=2, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Questions :**\n",
    "1. Pourquoi utilise-t-on `enum` pour le param√®tre operation ?\n",
    "2. Que se passe-t-il si le LLM essaie de passer une cha√Æne pour le param√®tre `a` ?\n",
    "3. Pourquoi la description est-elle importante pour chaque param√®tre ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approche API\n",
    "\n",
    "Maintenant faisons la m√™me chose avec le param√®tre `tools=` de l'API :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Appel avec l'API tools=\n",
    "response_api = client.chat.completions.create(\n",
    "    model=config[\"chat_deployment\"],\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Combien font 9712439 multipli√© par -138213 ?\"}],\n",
    "    tools=[outil_calculatrice],  # ‚úÖ On passe le sch√©ma structur√©\n",
    "    tool_choice=\"auto\" # On peut forcer ou d√©sactiver l'utilisation de certains outils\n",
    ")\n",
    "\n",
    "message = response_api.choices[0].message\n",
    "\n",
    "print(\"\\nR√âPONSE DU LLM (structure) :\")\n",
    "print(f\"- content : {message.content}\")\n",
    "print(f\"- tool_calls : {message.tool_calls}\")\n",
    "\n",
    "if message.tool_calls:\n",
    "    for tool_call in message.tool_calls:\n",
    "        print(f\"\\n‚úÖ L'API a AUTOMATIQUEMENT :\")\n",
    "        print(f\"   - Pars√© le nom de l'outil : {tool_call.function.name}\")\n",
    "        print(f\"   - Pars√© les arguments : {tool_call.function.arguments}\")\n",
    "        print(f\"   - Valid√© que 'operation' est dans l'enum\")\n",
    "        print(f\"   - V√©rifi√© les types (a et b sont des numbers)\")\n",
    "        \n",
    "        # Ex√©cution\n",
    "        arguments = json.loads(tool_call.function.arguments)\n",
    "        resultat = calculatrice(**arguments)\n",
    "        print(f\"\\n   üéØ R√©sultat : {resultat}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üí° R√©ponse √† la question : \"Que fait `tools=` ?\"\n",
    "\n",
    "Le param√®tre `tools=` :\n",
    "1. **Prend votre sch√©ma d'outil** (le JSON que vous d√©finissez)\n",
    "2. **L'int√®gre dans le contexte du LLM** (d'une mani√®re optimis√©e par OpenAI/Azure)\n",
    "4. **Garantit un format de sortie structur√©** (tool_calls avec validation)\n",
    "5. **Parse et valide automatiquement** les param√®tres\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approche API: Ex√©cuter l'Outil et Retourner les R√©sultats\n",
    "\n",
    "Le LLM ne fait que *demander* des appels d'outils. Nous devons :\n",
    "1. Ex√©cuter l'outil\n",
    "2. Retourner le r√©sultat au LLM\n",
    "3. Laisser le LLM formuler une r√©ponse finale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def executer_appel_outil(nom_outil: str, arguments_outil: dict):\n",
    "    \"\"\"Ex√©cute l'outil demand√©.\"\"\"\n",
    "    if nom_outil == \"calculatrice\":\n",
    "        return calculatrice(**arguments_outil)\n",
    "    else:\n",
    "        return f\"Erreur : Outil inconnu '{nom_outil}'\"\n",
    "\n",
    "def boucle_complete_appel_outils(message_utilisateur: str, outils: list):\n",
    "    \"\"\"Boucle compl√®te : LLM -> Ex√©cution Outil -> LLM -> R√©ponse Finale.\"\"\"\n",
    "    print(f\"Utilisateur : {message_utilisateur}\\n\")\n",
    "    \n",
    "    # √âtape 1: Appel initial au LLM\n",
    "    messages = [{\"role\": \"user\", \"content\": message_utilisateur}]\n",
    "    response = client.chat.completions.create(\n",
    "        model=config[\"chat_deployment\"],\n",
    "        messages=messages,\n",
    "        tools=outils,\n",
    "        tool_choice=\"auto\"\n",
    "    )\n",
    "    \n",
    "    print(\"D√©cision du LLM :\")\n",
    "    \n",
    "    message = response.choices[0].message\n",
    "    \n",
    "    # V√©rifier si le LLM veut utiliser des outils\n",
    "    if not message.tool_calls:\n",
    "        print(\"  Pas d'outil n√©cessaire, r√©ponse directe :\")\n",
    "        print(f\"  {message.content}\")\n",
    "        return\n",
    "    \n",
    "    # √âtape 2: Ex√©cuter les outils\n",
    "    messages.append(message)\n",
    "    \n",
    "    for tool_call in message.tool_calls:\n",
    "        print(f\"  Appel de l'outil : {tool_call.function.name}\")\n",
    "        arguments = json.loads(tool_call.function.arguments)\n",
    "        print(f\"  Avec arguments : {json.dumps(arguments, ensure_ascii=False)}\")\n",
    "        \n",
    "        resultat = executer_appel_outil(tool_call.function.name, arguments)\n",
    "        print(f\"  R√©sultat : {resultat}\\n\")\n",
    "        \n",
    "        messages.append({\n",
    "            \"role\": \"tool\",\n",
    "            \"tool_call_id\": tool_call.id,\n",
    "            \"name\": tool_call.function.name,\n",
    "            \"content\": str(resultat)\n",
    "        })\n",
    "    \n",
    "    # √âtape 3: Renvoyer les r√©sultats au LLM pour une r√©ponse finale\n",
    "    reponse_finale = client.chat.completions.create(\n",
    "        model=config[\"chat_deployment\"],\n",
    "        messages=messages\n",
    "    )\n",
    "    \n",
    "    print(\"R√©ponse Finale :\")\n",
    "    print(f\"  {reponse_finale.choices[0].message.content}\")\n",
    "\n",
    "# Test de la boucle compl√®te\n",
    "boucle_complete_appel_outils(\"Combien font 1547 divis√© par 23 ?\", [outil_calculatrice])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comprendre le Flux\n",
    "\n",
    "**Question** : Dans la cellule ci-dessus, identifiez les trois √©tapes :\n",
    "1. O√π le LLM d√©cide-t-il d'utiliser un outil ?\n",
    "2. O√π ex√©cutons-nous l'outil ?\n",
    "3. O√π le LLM voit-il le r√©sultat et formule-t-il la r√©ponse ?\n",
    "\n",
    "Essayez avec diff√©rentes questions :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# √Ä VOTRE TOUR : Testez avec vos questions\n",
    "cas_test = [\n",
    "    \"Combien font 892 multipli√© par 47 ?\",\n",
    "    \"Si j'ai 1000 euros et que je d√©pense 347, combien me reste-t-il ?\",\n",
    "    \"Combien font 2 + 2 ?\",  # Simple - utilisera-t-il quand m√™me l'outil ?\n",
    "]\n",
    "\n",
    "for question in cas_test:\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    boucle_complete_appel_outils(question, [outil_calculatrice])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pi√®ges Courants et Probl√®mes\n",
    "\n",
    "### Pi√®ge 1: Descriptions d'Outils Mal R√©dig√©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAUVAIS EXEMPLE : Description vague\n",
    "mauvais_outil_calculatrice = {\n",
    "    \"type\": \"function\",\n",
    "    \"function\": {\n",
    "        \"name\": \"outil\",\n",
    "        \"description\": \"outil\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"operation\": {\"type\": \"string\"},\n",
    "                \"a\": {\"type\": \"number\"},\n",
    "                \"b\": {\"type\": \"number\"}\n",
    "            },\n",
    "            \"required\": [\"operation\", \"a\", \"b\"]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Testez-le\n",
    "print(\"Test avec une MAUVAISE description d'outil :\")\n",
    "response = appeler_llm_avec_outils(\"Combien font 25 fois 4 ?\", [mauvais_outil_calculatrice])\n",
    "\n",
    "message = response.choices[0].message\n",
    "print(f\"Reponse du LLM : {message}\")\n",
    "for tool_call in message.tool_calls:\n",
    "    print()\n",
    "    # Ex√©cution\n",
    "    arguments = json.loads(tool_call.function.arguments)\n",
    "    resultat = calculatrice(**arguments)\n",
    "    print(resultat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question** : \n",
    "1. Qu'est ce qui ne va pas dans la description de l'outil ci dessus?\n",
    "2. corrige le pour obtenir le r√©sultat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pi√®ge 2: Param√®tres Requis Manquants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Que se passe-t-il si l'utilisateur ne fournit pas assez d'informations ?\n",
    "print(\"Test avec une question ambigu√´ :\")\n",
    "boucle_complete_appel_outils(\"Multiplie 5 par quelque chose\", [outil_calculatrice])\n",
    "\n",
    "# Le LLM va soit :\n",
    "# 1. Demander des pr√©cisions\n",
    "# 2. Faire des suppositions\n",
    "# 3. Retourner une erreur"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pi√®ge 3: Sur-utilisation des Outils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test : Questions simples qui n'ont pas besoin d'outils\n",
    "questions_simples = [\n",
    "    \"Combien font 2 + 2 ?\",\n",
    "    \"Est-ce que 10 est plus grand que 5 ?\",\n",
    "    \"Quel est le double de 50 ?\"\n",
    "]\n",
    "\n",
    "print(\"Test de questions simples :\")\n",
    "for q in questions_simples:\n",
    "    print(f\"\\nQuestion : {q}\")\n",
    "    response = appeler_llm_avec_outils(q, [outil_calculatrice])\n",
    "    \n",
    "    utilise_outil = response.choices[0].message.tool_calls is not None\n",
    "    print(f\"Utilise un outil : {utilise_outil}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pi√®ge 4: Ne Pas G√©rer les Erreurs d'Outils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Que se passe-t-il avec une division par z√©ro ?\n",
    "print(\"Test de la gestion des erreurs :\")\n",
    "boucle_complete_appel_outils(\"Utilise la calculatrice pour voir combien font 100 divis√© par 0 ?\", [outil_calculatrice])\n",
    "\n",
    "# Le LLM re√ßoit le message d'erreur et le g√®re avec √©l√©gance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice (facultatif) - Cr√©ez Votre Propre Outil\n",
    "\n",
    "Maintenant c'est √† vous ! Cr√©ez un outil simple et testez-le.\n",
    "\n",
    "**T√¢che** : Cr√©ez un outil \"analyseur_texte\" qui :\n",
    "- Prend une cha√Æne de texte en entr√©e\n",
    "- Retourne le nombre de mots et de caract√®res\n",
    "\n",
    "Compl√©tez le code ci-dessous :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# √âtape 1: Impl√©mentez la fonction\n",
    "def analyseur_texte(texte: str) -> dict:\n",
    "    \"\"\"Analyse un texte et retourne des statistiques.\"\"\"\n",
    "    # TODO: Impl√©mentez cette fonction\n",
    "    # Retournez un dictionnaire avec 'nombre_mots' et 'nombre_caracteres'\n",
    "    pass\n",
    "\n",
    "# √âtape 2: Cr√©ez le sch√©ma de l'outil\n",
    "outil_analyseur_texte = {\n",
    "    \"type\": \"function\",\n",
    "    \"function\": {\n",
    "        \"name\": \"analyseur_texte\",\n",
    "        \"description\": \"TODO: √âcrivez une description claire\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                # TODO: D√©finissez le param√®tre 'texte'\n",
    "            },\n",
    "            \"required\": [\"texte\"]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# √âtape 3: Testez-le\n",
    "# TODO: Appelez le LLM avec une question comme \"Combien de mots y a-t-il dans 'Bonjour le monde' ?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution (Ex√©cutez apr√®s avoir tent√© l'exercice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution\n",
    "def analyseur_texte(texte: str) -> dict:\n",
    "    \"\"\"Analyse un texte et retourne des statistiques.\"\"\"\n",
    "    mots = texte.split()\n",
    "    return {\n",
    "        \"nombre_mots\": len(mots),\n",
    "        \"nombre_caracteres\": len(texte),\n",
    "        \"nombre_caracteres_sans_espaces\": len(texte.replace(\" \", \"\"))\n",
    "    }\n",
    "\n",
    "outil_analyseur_texte = {\n",
    "    \"type\": \"function\",\n",
    "    \"function\": {\n",
    "        \"name\": \"analyseur_texte\",\n",
    "        \"description\": \"Analyse une cha√Æne de texte et retourne le nombre de mots, le nombre de caract√®res, et le nombre de caract√®res sans espaces.\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"texte\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"Le texte √† analyser\"\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"texte\"]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Mise √† jour de la fonction d'ex√©cution d'outil\n",
    "def executer_appel_outil_v2(nom_outil: str, arguments_outil: dict):\n",
    "    if nom_outil == \"calculatrice\":\n",
    "        return calculatrice(**arguments_outil)\n",
    "    elif nom_outil == \"analyseur_texte\":\n",
    "        return analyseur_texte(**arguments_outil)\n",
    "    else:\n",
    "        return f\"Erreur : Outil inconnu '{nom_outil}'\"\n",
    "\n",
    "# Fonction de boucle mise √† jour\n",
    "def boucle_complete_appel_outils_v2(message_utilisateur: str, outils: list):\n",
    "    print(f\"Utilisateur : {message_utilisateur}\\n\")\n",
    "    messages = [{\"role\": \"user\", \"content\": message_utilisateur}]\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=config[\"chat_deployment\"],\n",
    "        messages=messages,\n",
    "        tools=outils,\n",
    "        tool_choice=\"auto\"\n",
    "    )\n",
    "    \n",
    "    message = response.choices[0].message\n",
    "    \n",
    "    if not message.tool_calls:\n",
    "        print(f\"R√©ponse directe : {message.content}\")\n",
    "        return\n",
    "    \n",
    "    messages.append(message)\n",
    "    \n",
    "    for tool_call in message.tool_calls:\n",
    "        arguments = json.loads(tool_call.function.arguments)\n",
    "        resultat = executer_appel_outil_v2(tool_call.function.name, arguments)\n",
    "        print(f\"Outil utilis√© : {tool_call.function.name}\")\n",
    "        print(f\"R√©sultat : {resultat}\\n\")\n",
    "        \n",
    "        messages.append({\n",
    "            \"role\": \"tool\",\n",
    "            \"tool_call_id\": tool_call.id,\n",
    "            \"name\": tool_call.function.name,\n",
    "            \"content\": json.dumps(resultat, ensure_ascii=False) if isinstance(resultat, dict) else str(resultat)\n",
    "        })\n",
    "    \n",
    "    reponse_finale = client.chat.completions.create(\n",
    "        model=config[\"chat_deployment\"],\n",
    "        messages=messages\n",
    "    )\n",
    "    \n",
    "    print(\"R√©ponse Finale :\")\n",
    "    print(f\"  {reponse_finale.choices[0].message.content}\")\n",
    "\n",
    "# Testez-le\n",
    "boucle_complete_appel_outils_v2(\n",
    "    \"Combien de mots y a-t-il dans la phrase : 'Le petit renard brun saute par-dessus le chien paresseux' ?\",\n",
    "    [outil_analyseur_texte]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partie 8: Outils Multiples et S√©lection d'Outils\n",
    "\n",
    "Que se passe-t-il quand le LLM a acc√®s √† plusieurs outils ? Testons :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Donner au LLM les deux outils\n",
    "tous_les_outils = [outil_calculatrice, outil_analyseur_texte]\n",
    "\n",
    "questions_test = [\n",
    "    \"Combien font 45 fois 67 ?\",\n",
    "    \"Combien de mots y a-t-il dans 'Bonjour le monde' ?\",\n",
    "    \"Compte les caract√®res dans 'Programmation Python' et multiplie par 2\",  # N√©cessite les deux !\n",
    "]\n",
    "\n",
    "for question in questions_test:\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    boucle_complete_appel_outils_v2(question, tous_les_outils)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation Cl√©** : Le LLM peut :\n",
    "1. Choisir le bon outil pour la t√¢che\n",
    "2. Utiliser plusieurs outils en s√©quence\n",
    "3. Combiner les r√©sultats de diff√©rents outils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## R√©sum√© des Bonnes Pratiques\n",
    "\n",
    "### √âcrire de Bonnes Descriptions d'Outils :\n",
    "1. **Soyez sp√©cifique** : Indiquez clairement ce que fait l'outil\n",
    "2. **Utilisez des enums** : Restreignez les param√®tres string aux valeurs valides\n",
    "3. **D√©crivez les param√®tres** : Chaque param√®tre a besoin d'une description claire\n",
    "4. **Marquez les champs requis** : Sp√©cifiez quels param√®tres sont obligatoires\n",
    "\n",
    "### Erreurs Courantes √† √âviter :\n",
    "1. Descriptions d'outils vagues\n",
    "2. Descriptions de param√®tres manquantes\n",
    "3. Ne pas g√©rer les erreurs d'outils\n",
    "4. Oublier de renvoyer les r√©sultats des outils au LLM\n",
    "5. Cr√©er des outils pour des choses que le LLM peut faire directement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comprendre le Flux d'Appel d'Outils (Diagramme)\n",
    "\n",
    "```\n",
    "Question Utilisateur\n",
    "     |\n",
    "     v\n",
    "LLM (avec d√©finitions d'outils)\n",
    "     |\n",
    "     +---> D√©cision : Utiliser un outil ?\n",
    "     |         |\n",
    "     |         +---> Non : Retourner r√©ponse directe\n",
    "     |         |\n",
    "     |         +---> Oui : G√©n√©rer bloc tool_use\n",
    "     v\n",
    "Ex√©cution de l'Outil (votre code)\n",
    "     |\n",
    "     v\n",
    "R√©sultat de l'Outil\n",
    "     |\n",
    "     v\n",
    "LLM (avec r√©sultat de l'outil)\n",
    "     |\n",
    "     v\n",
    "R√©ponse Finale √† l'Utilisateur\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Vous comprenez maintenant :\n",
    "- Comment les LLMs utilisent les outils via du JSON structur√©\n",
    "- Comment √©crire des sch√©mas d'outils\n",
    "- La boucle compl√®te d'appel d'outils\n",
    "- Les pi√®ges courants et comment les √©viter\n",
    "\n",
    "**Prochaines √âtapes** : Dans le tutoriel principal, vous verrez comment LangGraph automatise cette boucle d'appel d'outils et permet des comportements agentiques complexes avec plusieurs outils travaillant ensemble !"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
