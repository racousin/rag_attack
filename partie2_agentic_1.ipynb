{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Partie 2 : Comprendre les Outils et les Agents\n",
    "\n",
    "Ce notebook couvre deux concepts fondamentaux :\n",
    "1. **Les Outils (Function Calling)** : Comment les LLMs utilisent des fonctions externes\n",
    "2. **LangGraph** : Un framework pour cr√©er des agents sous forme de graphes d'√©tats\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapitre 1 : Les Outils (Function Calling)\n",
    "\n",
    "### Qu'est-ce qu'un Outil ?\n",
    "\n",
    "Les outils permettent aux LLMs de :\n",
    "- Effectuer des calculs\n",
    "- Interroger des bases de donn√©es\n",
    "- Appeler des APIs externes\n",
    "\n",
    "**Concept cl√©** : Les LLMs n'ex√©cutent pas directement les outils. Ils **g√©n√®rent des instructions structur√©es** qui nous indiquent quel outil appeler et avec quels param√®tres."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "config = {\n",
    "    \"openai_endpoint\": \"\",\n",
    "    \"openai_key\": \"\",\n",
    "    \"chat_deployment\": \"\"\n",
    "}\n",
    "\n",
    "client = AzureOpenAI(\n",
    "    api_key=config[\"openai_key\"],\n",
    "    api_version=\"2024-02-01\",\n",
    "    azure_endpoint=config[\"openai_endpoint\"]\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Client Azure OpenAI initialis√©\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exemple : Une Calculatrice Simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculatrice(operation: str, a: float, b: float) -> float:\n",
    "    \"\"\"Une calculatrice simple qui effectue des op√©rations de base.\"\"\"\n",
    "    if operation == \"additionner\":\n",
    "        return a + b\n",
    "    elif operation == \"soustraire\":\n",
    "        return a - b\n",
    "    elif operation == \"multiplier\":\n",
    "        return a * b\n",
    "    elif operation == \"diviser\":\n",
    "        if b == 0:\n",
    "            return \"Erreur : Division par z√©ro\"\n",
    "        return a / b\n",
    "    else:\n",
    "        return f\"Erreur : Op√©ration inconnue '{operation}'\"\n",
    "\n",
    "print(f\"Test: 25 √ó 4 = {calculatrice('multiplier', 25, 4)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pourquoi un LLM a-t-il besoin d'une calculatrice ?\n",
    "\n",
    "Testons le LLM sur un calcul complexe :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"multiplie 9712439 et -138213\"  # Bonne r√©ponse: -1342385331507\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=config[\"chat_deployment\"],\n",
    "    messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    ")\n",
    "\n",
    "print(\"R√âPONSE DU LLM (sans outil) :\")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Questions :**\n",
    "1. La r√©ponse est-elle correcte ? Essayez plusieurs fois.\n",
    "2. Comment pourrait-on permettre au LLM d'utiliser notre calculatrice ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Approche Manuelle\n",
    "\n",
    "### √âtape 1 : D√©crire l'outil dans le prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "description_outil = \"\"\"**calculatrice** : Effectue des op√©rations arithm√©tiques\n",
    "Param√®tres :\n",
    "- operation: \"additionner\", \"soustraire\", \"multiplier\", ou \"diviser\"\n",
    "- a: le premier nombre\n",
    "- b: le deuxi√®me nombre\n",
    "\n",
    "Pour utiliser un outil, r√©ponds avec CE FORMAT JSON EXACT :\n",
    "```json\n",
    "{\"outil\": \"calculatrice\", \"arguments\": {\"operation\": \"multiplier\", \"a\": 25, \"b\": 4}}\n",
    "```\"\"\"\n",
    "\n",
    "message_utilisateur = \"Combien font 9712439 multipli√© par -138213 ?\"\n",
    "\n",
    "prompt = f\"\"\"Tu es un assistant avec acc√®s √† des outils.\n",
    "\n",
    "{description_outil}\n",
    "\n",
    "Question : {message_utilisateur}\"\"\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=config[\"chat_deployment\"],\n",
    "    messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    ")\n",
    "\n",
    "reponse_texte = response.choices[0].message.content\n",
    "print(\"R√âPONSE DU LLM :\")\n",
    "print(reponse_texte)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### √âtape 2 : Parser le JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "try:\n",
    "    json_match = re.search(r'```json\\s*(\\{.*?\\})\\s*```', reponse_texte, re.DOTALL)\n",
    "    \n",
    "    if json_match:\n",
    "        json_str = json_match.group(1)\n",
    "    else:\n",
    "        json_str = reponse_texte.strip()\n",
    "    \n",
    "    appel_outil = json.loads(json_str)\n",
    "    nom_outil = appel_outil.get(\"outil\")\n",
    "    arguments = appel_outil.get(\"arguments\")\n",
    "    \n",
    "    print(f\"‚úÖ Outil : {nom_outil}\")\n",
    "    print(f\"‚úÖ Arguments : {arguments}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Erreur de parsing : {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### √âtape 3 : Ex√©cuter l'outil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bonne r√©ponse: -1342385331507\n",
    "if nom_outil == \"calculatrice\":\n",
    "    resultat = calculatrice(**arguments)\n",
    "    print(f\"‚úÖ R√©sultat : {resultat}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Questions :**\n",
    "1. La r√©ponse est-elle correcte maintenant ?\n",
    "2. Quels sont les probl√®mes de cette approche manuelle ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Approche API (tools=)\n",
    "\n",
    "Les APIs de LLM int√®grent une notion d'outils pour faciliter les interactions.\n",
    "\n",
    "### Sch√©ma de l'outil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outil_calculatrice = {\n",
    "    \"type\": \"function\",\n",
    "    \"function\": {\n",
    "        \"name\": \"calculatrice\",\n",
    "        \"description\": \"Effectue des op√©rations arithm√©tiques (additionner, soustraire, multiplier, diviser).\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"operation\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"enum\": [\"additionner\", \"soustraire\", \"multiplier\", \"diviser\"],\n",
    "                    \"description\": \"L'op√©ration √† effectuer\"\n",
    "                },\n",
    "                \"a\": {\"type\": \"number\", \"description\": \"Le premier nombre\"},\n",
    "                \"b\": {\"type\": \"number\", \"description\": \"Le deuxi√®me nombre\"}\n",
    "            },\n",
    "            \"required\": [\"operation\", \"a\", \"b\"]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "print(json.dumps(outil_calculatrice, indent=2, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Appel avec tools="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=config[\"chat_deployment\"],\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Combien font 9712439 multipli√© par -138213 ?\"}],\n",
    "    tools=[outil_calculatrice],\n",
    "    tool_choice=\"auto\"\n",
    ")\n",
    "\n",
    "message = response.choices[0].message\n",
    "\n",
    "if message.tool_calls:\n",
    "    for tool_call in message.tool_calls:\n",
    "        print(f\"‚úÖ Outil : {tool_call.function.name}\")\n",
    "        print(f\"‚úÖ Arguments : {tool_call.function.arguments}\")\n",
    "        \n",
    "        arguments = json.loads(tool_call.function.arguments)\n",
    "        resultat = calculatrice(**arguments)\n",
    "        print(f\"‚úÖ R√©sultat : {resultat}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boucle Compl√®te : LLM ‚Üí Outil ‚Üí LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def executer_outil(nom_outil: str, arguments: dict):\n",
    "    \"\"\"Ex√©cute l'outil demand√©.\"\"\"\n",
    "    if nom_outil == \"calculatrice\":\n",
    "        return calculatrice(**arguments)\n",
    "    return f\"Erreur : Outil inconnu '{nom_outil}'\"\n",
    "\n",
    "def boucle_agent(message_utilisateur: str, outils: list):\n",
    "    \"\"\"Boucle compl√®te : LLM ‚Üí Outil ‚Üí R√©ponse Finale.\"\"\"\n",
    "    print(f\"üë§ Utilisateur : {message_utilisateur}\\n\")\n",
    "    \n",
    "    messages = [{\"role\": \"user\", \"content\": message_utilisateur}]\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=config[\"chat_deployment\"],\n",
    "        messages=messages,\n",
    "        tools=outils,\n",
    "        tool_choice=\"auto\"\n",
    "    )\n",
    "    \n",
    "    message = response.choices[0].message\n",
    "    \n",
    "    if not message.tool_calls:\n",
    "        print(f\"ü§ñ R√©ponse directe : {message.content}\")\n",
    "        return\n",
    "    \n",
    "    messages.append(message)\n",
    "    \n",
    "    for tool_call in message.tool_calls:\n",
    "        arguments = json.loads(tool_call.function.arguments)\n",
    "        print(f\"üîß Outil : {tool_call.function.name}({arguments})\")\n",
    "        \n",
    "        resultat = executer_outil(tool_call.function.name, arguments)\n",
    "        print(f\"üìä R√©sultat : {resultat}\\n\")\n",
    "        \n",
    "        messages.append({\n",
    "            \"role\": \"tool\",\n",
    "            \"tool_call_id\": tool_call.id,\n",
    "            \"name\": tool_call.function.name,\n",
    "            \"content\": str(resultat)\n",
    "        })\n",
    "    \n",
    "    reponse_finale = client.chat.completions.create(\n",
    "        model=config[\"chat_deployment\"],\n",
    "        messages=messages\n",
    "    )\n",
    "    \n",
    "    print(f\"ü§ñ R√©ponse : {reponse_finale.choices[0].message.content}\")\n",
    "\n",
    "# Test\n",
    "boucle_agent(\"Combien font 1547 divis√© par 23 ?\", [outil_calculatrice])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tests suppl√©mentaires\n",
    "questions = [\n",
    "    \"Combien font 892 multipli√© par 47 ?\",\n",
    "    \"Si j'ai 1000 euros et que je d√©pense 347, combien me reste-t-il ?\",\n",
    "]\n",
    "\n",
    "for q in questions:\n",
    "    print(\"=\" * 60)\n",
    "    boucle_agent(q, [outil_calculatrice])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Pi√®ges Courants\n",
    "\n",
    "### Pi√®ge 1 : Descriptions vagues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAUVAIS : Description vague\n",
    "mauvais_outil = {\n",
    "    \"type\": \"function\",\n",
    "    \"function\": {\n",
    "        \"name\": \"outil\",\n",
    "        \"description\": \"outil\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"operation\": {\"type\": \"string\"},\n",
    "                \"a\": {\"type\": \"number\"},\n",
    "                \"b\": {\"type\": \"number\"}\n",
    "            },\n",
    "            \"required\": [\"operation\", \"a\", \"b\"]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"Test avec une MAUVAISE description :\")\n",
    "boucle_agent(\"Combien font 25 fois 4 ?\", [mauvais_outil])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pi√®ge 2 : Gestion des erreurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Test de la division par z√©ro :\")\n",
    "boucle_agent(\"Combien font 100 divis√© par 0 ?\", [outil_calculatrice])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## R√©sum√© : Flux d'Appel d'Outils\n",
    "\n",
    "```\n",
    "Question Utilisateur\n",
    "        ‚Üì\n",
    "   LLM (avec outils)\n",
    "        ‚Üì\n",
    "   tool_calls ? ‚îÄ‚îÄNon‚îÄ‚îÄ‚Üí R√©ponse directe\n",
    "        ‚îÇ\n",
    "       Oui\n",
    "        ‚Üì\n",
    "   Ex√©cution Outil\n",
    "        ‚Üì\n",
    "   R√©sultat ‚Üí LLM\n",
    "        ‚Üì\n",
    "   R√©ponse Finale\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Chapitre 2 : Introduction √† LangGraph\n",
    "\n",
    "## Qu'est-ce que LangGraph ?\n",
    "\n",
    "**LangGraph** permet de cr√©er des agents LLM sous forme de **graphes d'√©tats**.\n",
    "\n",
    "Au lieu de g√©rer manuellement la boucle, LangGraph offre :\n",
    "- Une **abstraction claire** : N≈ìuds et ar√™tes repr√©sentent le flux\n",
    "- Une **gestion automatique** : La boucle agent ‚Üí outil ‚Üí agent est g√©r√©e automatiquement\n",
    "- Une **extensibilit√©** : Facile d'ajouter de nouveaux comportements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration LangGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, MessagesState, START, END\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain_core.tools import tool\n",
    "from typing import Literal\n",
    "\n",
    "print(\"‚úÖ Imports LangGraph r√©ussis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D√©finir l'outil avec le d√©corateur @tool\n",
    "\n",
    "Le d√©corateur `@tool` g√©n√®re automatiquement le sch√©ma JSON √† partir :\n",
    "- Des types Python (str, float ‚Üí string, number)\n",
    "- De `Literal` pour les enums\n",
    "- De la docstring pour les descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def calculatrice(\n",
    "    operation: Literal[\"additionner\", \"soustraire\", \"multiplier\", \"diviser\"],\n",
    "    a: float,\n",
    "    b: float\n",
    ") -> float:\n",
    "    \"\"\"Effectue des op√©rations arithm√©tiques de base.\n",
    "    \n",
    "    Args:\n",
    "        operation: L'op√©ration √† effectuer\n",
    "        a: Le premier nombre\n",
    "        b: Le deuxi√®me nombre\n",
    "    \"\"\"\n",
    "    if operation == \"additionner\":\n",
    "        return a + b\n",
    "    elif operation == \"soustraire\":\n",
    "        return a - b\n",
    "    elif operation == \"multiplier\":\n",
    "        return a * b\n",
    "    elif operation == \"diviser\":\n",
    "        return a / b if b != 0 else \"Erreur : Division par z√©ro\"\n",
    "\n",
    "# Test\n",
    "print(f\"Test: 25 √ó 4 = {calculatrice.invoke({'operation': 'multiplier', 'a': 25, 'b': 4})}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Voir le sch√©ma g√©n√©r√© automatiquement\n",
    "print(\"Sch√©ma g√©n√©r√© par @tool :\")\n",
    "print(json.dumps(calculatrice.args_schema.model_json_schema(), indent=2, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cr√©er le LLM avec les outils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = AzureChatOpenAI(\n",
    "    api_key=config[\"openai_key\"],\n",
    "    api_version=\"2024-02-01\",\n",
    "    azure_endpoint=config[\"openai_endpoint\"],\n",
    "    model=config[\"chat_deployment\"],\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "tools = [calculatrice]\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "print(\"‚úÖ LLM configur√© avec les outils\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construire le Graphe\n",
    "\n",
    "Un graphe LangGraph se compose de :\n",
    "1. **N≈ìuds** : Fonctions qui traitent l'√©tat\n",
    "2. **Ar√™tes** : Transitions entre n≈ìuds\n",
    "3. **√âtat** : Donn√©es qui circulent (ici, les messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# N≈ìud Agent : appelle le LLM\n",
    "def call_agent(state: MessagesState):\n",
    "    response = llm_with_tools.invoke(state[\"messages\"])\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "# N≈ìud Outils : ex√©cute les outils demand√©s\n",
    "tool_node = ToolNode(tools)\n",
    "\n",
    "# Routage : continuer vers les outils ou terminer ?\n",
    "def should_continue(state: MessagesState):\n",
    "    last_message = state[\"messages\"][-1]\n",
    "    if last_message.tool_calls:\n",
    "        return \"tools\"\n",
    "    return END\n",
    "\n",
    "print(\"‚úÖ N≈ìuds et routage d√©finis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construire le graphe\n",
    "workflow = StateGraph(MessagesState)\n",
    "\n",
    "# Ajouter les n≈ìuds\n",
    "workflow.add_node(\"agent\", call_agent)\n",
    "workflow.add_node(\"tools\", tool_node)\n",
    "\n",
    "# D√©finir les ar√™tes\n",
    "workflow.add_edge(START, \"agent\")\n",
    "workflow.add_conditional_edges(\"agent\", should_continue, {\"tools\": \"tools\", END: END})\n",
    "workflow.add_edge(\"tools\", \"agent\")\n",
    "\n",
    "# Compiler\n",
    "app = workflow.compile()\n",
    "\n",
    "print(\"‚úÖ Graphe compil√©\")\n",
    "print(\"\\nStructure : START ‚Üí agent ‚Üí [tools ‚Üí agent]* ‚Üí END\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualiser le graphe\n",
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(app.get_graph().draw_mermaid_png()))\n",
    "except:\n",
    "    print(\"Visualisation non disponible\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tester l'Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Combien font 9712439 multipli√© par -138213 ?\"\n",
    "\n",
    "result = app.invoke({\"messages\": [HumanMessage(content=question)]})\n",
    "\n",
    "print(f\"‚ùì Question : {question}\")\n",
    "print(f\"ü§ñ R√©ponse : {result['messages'][-1].content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observer le Flux avec Streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Si je multiplie 847 par 123, puis divise par 11, quel est le r√©sultat ?\"\n",
    "\n",
    "print(f\"‚ùì Question : {question}\\n\")\n",
    "print(\"FLUX D'EX√âCUTION :\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for i, step in enumerate(app.stream({\"messages\": [HumanMessage(content=question)]}), 1):\n",
    "    for node_name, node_state in step.items():\n",
    "        print(f\"\\n√âtape {i} - {node_name}\")\n",
    "        \n",
    "        if node_name == \"agent\":\n",
    "            last_msg = node_state[\"messages\"][-1]\n",
    "            if hasattr(last_msg, 'tool_calls') and last_msg.tool_calls:\n",
    "                for tc in last_msg.tool_calls:\n",
    "                    print(f\"   ‚Üí Appel : {tc['name']}({tc['args']})\")\n",
    "            else:\n",
    "                print(f\"   ‚Üí R√©ponse finale pr√™te\")\n",
    "        \n",
    "        elif node_name == \"tools\":\n",
    "            for msg in node_state[\"messages\"]:\n",
    "                print(f\"   ‚Üí R√©sultat : {msg.content}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(f\"ü§ñ R√©ponse : {list(step.values())[0]['messages'][-1].content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## R√©sum√©\n",
    "\n",
    "### Ce que nous avons appris :\n",
    "\n",
    "1. **Function Calling** : Les LLMs g√©n√®rent des instructions structur√©es pour appeler des outils\n",
    "2. **Sch√©ma d'outil** : Description JSON qui permet au LLM de comprendre l'outil\n",
    "3. **Boucle Agent** : LLM ‚Üí Outil ‚Üí LLM ‚Üí R√©ponse\n",
    "4. **LangGraph** : Framework qui automatise cette boucle avec des graphes d'√©tats\n",
    "\n",
    "### Prochaines √©tapes :\n",
    "\n",
    "Dans les prochains notebooks, nous verrons des cas d'usage concrets avec des outils RAG, SQL, et API."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
