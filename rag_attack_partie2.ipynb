{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/racousin/rag_attack/blob/main/rag_attack.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Initial pour Google Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone the repository\n",
    "!git clone https://github.com/racousin/rag_attack.git\n",
    "%cd rag_attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run installation script\n",
    "!bash install_colab.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the rag_attack package\n",
    "!pip install -e ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "⚠️ **Important**: Remplacez les valeurs vides ci-dessous avec vos propres credentials Azure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration - DEMANDEZ VOS CREDENTIALS\n",
    "config = {\n",
    "    'search_endpoint': '',  # Ex: 'https://your-search.search.windows.net'\n",
    "    'search_key': '',  # Votre clé Azure Search\n",
    "    'sql_server': '',  # Ex: 'your-server.database.windows.net'\n",
    "    'sql_database': '',  # Nom de votre base de données\n",
    "    'sql_username': '',  # Username SQL\n",
    "    'sql_password': '',  # Password SQL\n",
    "    'api_base_url': '',  # Ex: 'https://your-api.azurewebsites.net/api'\n",
    "    'openai_endpoint': '',  # Ex: 'https://your-region.api.cognitive.microsoft.com/'\n",
    "    'openai_key': '',  # Votre clé OpenAI/Azure OpenAI\n",
    "    'chat_deployment': ''  # Ex: 'gpt-4' ou 'gpt-35-turbo'\n",
    "}\n",
    "\n",
    "# Validate configuration using the rag_attack package\n",
    "from rag_attack import validate_config, test_connection\n",
    "\n",
    "# Test that the package is loaded\n",
    "print(test_connection())\n",
    "\n",
    "# Validate configuration\n",
    "is_valid, message = validate_config(config)\n",
    "if is_valid:\n",
    "    print(\"✅\", message)\n",
    "else:\n",
    "    print(\"❌\", message)\n",
    "    print(\"\\nVeuillez remplir tous les champs de configuration avant de continuer.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.1 Setup & Imports\n",
    "# - Install langgraph, langchain, openai/anthropic\n",
    "\n",
    "# 1.2 Simple Agent Definition\n",
    "# - Create basic StateGraph\n",
    "# - Define agent state (messages, context)\n",
    "# - Add single LLM node with conditional edges\n",
    "\n",
    "# 1.3 Tool Integration\n",
    "# - Define search_tool function\n",
    "# - Bind tool to agent\n",
    "# - Show tool calling in action\n",
    "\n",
    "# 1.4 Embedding Setup\n",
    "# - Initialize embedding model\n",
    "# - Create simple vector store\n",
    "# - Demonstrate similarity search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.1 Planner Agent Architecture\n",
    "# - Define PlannerState with todo list\n",
    "# - Create plan generation node\n",
    "# - Create execution tracking node\n",
    "\n",
    "# 2.2 Implementation\n",
    "# - Build task decomposition prompt\n",
    "# - Create todo queue management\n",
    "# - Add replanning capability on failure\n",
    "\n",
    "# 2.3 Example: Multi-step Research Task\n",
    "# - Query → Plan → Execute → Verify loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.1 Router Agent Architecture\n",
    "# - Define RouterState with intent classification\n",
    "# - Create routing logic node\n",
    "\n",
    "# 3.2 Tool Registry\n",
    "# - Register existing tools (search, calculator, database)\n",
    "# - Define routing rules/conditions\n",
    "# - Implement tool selection logic\n",
    "\n",
    "# 3.3 Example: Dynamic Tool Selection\n",
    "# - User query → Intent → Route → Execute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.1 Traditional Tools\n",
    "# - Function-based tools\n",
    "# - Direct integration\n",
    "# - Synchronous execution\n",
    "\n",
    "# 4.2 MCP (Model Context Protocol) Tools\n",
    "# - Server-client architecture\n",
    "# - Standardized protocol\n",
    "# - Tool discovery and capabilities\n",
    "\n",
    "# 4.3 Comparison Table & When to Use Each"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w0QZQmtDHGyw"
   },
   "source": [
    "# 2/ RAG Agentique simple\n",
    "### -> 2 sources de données : bases SQL et documentation technique (manuels)\n",
    "- L'orchestrateur choisit quels tools utiliser et renvoie une réponse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Dr1lfjtqHnhd"
   },
   "outputs": [],
   "source": [
    "# Embedding model (chargé une seule fois)\n",
    "def _get_embedder(model_name: str = \"sentence-transformers/all-MiniLM-L6-v2\"):\n",
    "    \"\"\"Charge une seule fois le modèle d'embedding HuggingFace.\"\"\"\n",
    "    global _EMBED_MODEL\n",
    "    if _EMBED_MODEL is None:\n",
    "        from sentence_transformers import SentenceTransformer\n",
    "        _EMBED_MODEL = SentenceTransformer(model_name)\n",
    "    return _EMBED_MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MOadJYQeIWbu"
   },
   "source": [
    "Première étape : définir les outils utilisables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-4naC0O6HX4e"
   },
   "outputs": [],
   "source": [
    "# DEBUG helpers : simple préfixe pour repérer les traces\n",
    "DBG = lambda msg: print(f\"[DBG] {msg}\")\n",
    "\n",
    "# Définition des Tools :\n",
    "\n",
    "# La fonction suivante permet d'aller chercher via recherche sémantique un texte répondant à une question.\n",
    "# Ce code est grandement inspiré de la classe précédente, mais sans génération de réponse directe\n",
    "@tool\n",
    "def search_documents(query: str, top_results: int = 3) -> str:\n",
    "    \"\"\"\n",
    "    Recherche sémantique dans l’index Azure Cognitive Search **documents**.\n",
    "\n",
    "    ⚙️  Fonctionnement\n",
    "    ------------------\n",
    "    1. Encode la requête utilisateur avec le modèle Sentence-Transformers\n",
    "       déjà utilisé à l’indexation (cosine / dot product selon la config).\n",
    "    2. Envoie une requête vectorielle (API `VectorizedQuery` ou `Vector`)\n",
    "       et récupère les *k* documents les plus proches.\n",
    "    3. Formate la réponse en Markdown :\n",
    "       **n°. filename** – aperçu 200 caractères – *type* – *score*.\n",
    "\n",
    "    Paramètres\n",
    "    ----------\n",
    "    query : str\n",
    "        Texte brut de la question / mot-clé à rechercher.\n",
    "    top_results : int, default = 3\n",
    "        Nombre maximum de documents à renvoyer.\n",
    "\n",
    "    Retour\n",
    "    ------\n",
    "    str\n",
    "        - Une liste Markdown des résultats.\n",
    "        - “Aucun document…” si rien trouvé.\n",
    "        - Message d’erreur clair en cas d’exception.\n",
    "    \"\"\"\n",
    "\n",
    "    client = SearchClient(config[\"search_endpoint\"], \"documents\",\n",
    "                          AzureKeyCredential(config[\"search_key\"]))\n",
    "    vec = _EMBED_MODEL.encode(query).tolist()\n",
    "\n",
    "    # Choix API Vector / VectorizedQuery selon SDK\n",
    "    try:\n",
    "        from azure.search.documents.models import VectorizedQuery\n",
    "        res = client.search(search_text=\"*\",\n",
    "                            vector_queries=[VectorizedQuery(vector=vec,\n",
    "                                                            k=top_results,\n",
    "                                                            fields=\"embedding\")])\n",
    "    except ImportError:\n",
    "        from azure.search.documents.models import Vector\n",
    "        res = client.search(search_text=\"*\",\n",
    "                            vector=Vector(value=vec, k=top_results,\n",
    "                                          fields=\"embedding\"))\n",
    "    docs = list(res)\n",
    "    if not docs:\n",
    "        return f\"Aucun document pour « {query} ».\"\n",
    "\n",
    "    out: List[str] = []\n",
    "    for i, d in enumerate(docs, 1):\n",
    "        snippet = (d.get(\"content\", \"\")[:200] + \"…\").replace(\"\\n\", \" \")\n",
    "        out.append(f\"**{i}. {d.get('filename','?')}** – {snippet}\")\n",
    "    return \"\\n\".join(out)\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "# Ce tool permet d'explorer les tables SQL\n",
    "@tool\n",
    "def explore_database_schema(table_name: str = None) -> str:\n",
    "    \"\"\"\n",
    "    Explore la base SQL Server VéloCorp :\n",
    "\n",
    "    - Sans argument → liste toutes les tables.\n",
    "    - Avec `table_name` → détail des colonnes de cette table.\n",
    "\n",
    "    Paramètres\n",
    "    ----------\n",
    "    table_name : str | None\n",
    "        Nom exact de la table (sensible à la casse selon la collation).\n",
    "\n",
    "    Retour\n",
    "    ------\n",
    "    str\n",
    "        - Markdown listant les tables OU\n",
    "        - Tableau Markdown « colonne / type » pour la table ciblée\n",
    "        - Message d’erreur lisible si la table n’existe pas.\n",
    "\n",
    "    Bonnes pratiques\n",
    "    ----------------\n",
    "    - Appeler cette fonction **avant** de composer une requête SQL complexe.\n",
    "    - Coupler avec `query_database` pour inspecter un échantillon.\n",
    "    \"\"\"\n",
    "    conn = (f\"DRIVER={{ODBC Driver 18 for SQL Server}};\"\n",
    "            f\"SERVER={config['sql_server']};DATABASE={config['sql_database']};\"\n",
    "            f\"UID={config['sql_username']};PWD={config['sql_password']};\"\n",
    "            \"Encrypt=yes;TrustServerCertificate=no;Connection Timeout=30;\")\n",
    "    with pyodbc.connect(conn) as cnx:\n",
    "        cur = cnx.cursor()\n",
    "        if table_name is None:\n",
    "            cur.execute(\"SELECT TABLE_NAME FROM INFORMATION_SCHEMA.TABLES \"\n",
    "                        \"WHERE TABLE_TYPE='BASE TABLE' ORDER BY 1\")\n",
    "            tables = \"\\n\".join(\"- \" + r[0] for r in cur.fetchall())\n",
    "            DBG(\"Liste des tables SQL :\\n\" + tables)\n",
    "            return tables\n",
    "\n",
    "        cur.execute(\"SELECT COLUMN_NAME, DATA_TYPE \"\n",
    "                    \"FROM INFORMATION_SCHEMA.COLUMNS WHERE TABLE_NAME=?\",\n",
    "                    table_name)\n",
    "        cols = cur.fetchall()\n",
    "        if not cols:\n",
    "            DBG(f\"Table introuvable : {table_name}\")\n",
    "            return f\"Table « {table_name} » introuvable.\"\n",
    "        detail = f\"**{table_name}**\\n\" + \"\\n\".join(f\"- {c[0]} ({c[1]})\"\n",
    "                                                   for c in cols)\n",
    "        DBG(f\"Schéma de {table_name} :\\n\" + detail)\n",
    "        return detail\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "# Ce Tool permet de faire une requête au serveur SQL\n",
    "@tool\n",
    "def query_database(sql_query: str) -> str:\n",
    "    \"\"\"\n",
    "    Exécute une requête SELECT uniquement sur SQL Server.\n",
    "\n",
    "    Sécurité : toute commande non-`SELECT` est rejetée immédiatement.\n",
    "\n",
    "    Paramètres\n",
    "    ----------\n",
    "    sql_query : str\n",
    "        Requête SQL complète (peut inclure JOIN, CTE, OFFSET/FETCH, etc.).\n",
    "\n",
    "    Retour\n",
    "    ------\n",
    "    str\n",
    "        - Tableau Markdown (max 10 lignes)\n",
    "        - “Aucun résultat.” si la sélection est vide\n",
    "        - Message d’erreur enrichi (syntaxe, table inconnue, permissions…).\n",
    "\n",
    "    Exemple\n",
    "    -------\n",
    "    ```python\n",
    "    query_database(\n",
    "        \\\"\\\"\\\"SELECT TOP 5 customer_id, SUM(total) AS CA\n",
    "            FROM invoices GROUP BY customer_id ORDER BY CA DESC\\\"\\\"\\\")\n",
    "    ```\n",
    "    \"\"\"\n",
    "    # 1) Sécurité basique : on bloque tout ce qui n’est pas SELECT\n",
    "    if not sql_query.strip().upper().startswith(\"SELECT\"):\n",
    "        print(\"[DBG] Blocage sécurité : non-SELECT\")\n",
    "        return \"Seules les requêtes SELECT sont autorisées.\"\n",
    "\n",
    "    # 2) Connexion SQL Server\n",
    "    conn_str = (f\"DRIVER={{ODBC Driver 18 for SQL Server}};\"\n",
    "                f\"SERVER={config['sql_server']};DATABASE={config['sql_database']};\"\n",
    "                f\"UID={config['sql_username']};PWD={config['sql_password']};\"\n",
    "                \"Encrypt=yes;TrustServerCertificate=no;Connection Timeout=30;\")\n",
    "\n",
    "    print(\"[DBG] SQL envoyé :\")\n",
    "    print(sql_query)\n",
    "\n",
    "    with pyodbc.connect(conn_str) as conn:\n",
    "        cur = conn.cursor()\n",
    "        cur.execute(sql_query)\n",
    "\n",
    "        cols = [d[0] for d in cur.description]\n",
    "        rows = cur.fetchmany(max_rows)        # ⚠️ on charge max_rows, pas tout\n",
    "\n",
    "    # 3) Debug : combien de lignes ont été renvoyées ?\n",
    "    print(f\"[DBG] Lignes ramenées : {len(rows)} / limite affichage {max_rows}\")\n",
    "\n",
    "    if not rows:\n",
    "        print(\"[DBG] Colonnes reçues :\", cols)\n",
    "        return \"Aucun résultat.\"\n",
    "\n",
    "    # 4) Formatage Markdown (identique à ta version)\n",
    "    header = \" | \".join(cols)\n",
    "    sep    = \"-\" * len(header)\n",
    "    body   = [\" | \".join(str(c) for c in r) for r in rows]\n",
    "    return \"```\\n\" + \"\\n\".join([header, sep, *body]) + \"\\n```\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NKp8rMQzIa44"
   },
   "source": [
    "Deuxième étape : contruiure l'agent LangGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EHizjW1SIBSL"
   },
   "outputs": [],
   "source": [
    "# Construction de l'agent LangGraph\n",
    "\n",
    "# LLM (Azure OpenAI ou OpenAI “classique”)\n",
    "llm = AzureChatOpenAI(\n",
    "    azure_endpoint  = config[\"openai_endpoint\"],\n",
    "    api_key         = config[\"openai_key\"],\n",
    "    deployment_name = config[\"chat_deployment\"],\n",
    "    api_version     = \"2024-02-15-preview\"\n",
    ")\n",
    "\n",
    "# Bind des outils → le LLM générera directement les appels\n",
    "llm_tools = llm.bind_tools([search_documents,\n",
    "                            explore_database_schema,\n",
    "                            query_database])\n",
    "\n",
    "# État pour LangGraph\n",
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "def agent_node(state: AgentState):\n",
    "    system = \"\"\"\n",
    "    Tu es **VéloCorpGPT**, assistant technique & data.\n",
    "\n",
    "    Outils disponibles\n",
    "    ------------------\n",
    "    1. `search_documents` : recherche sémantique dans la doc interne (manuel, FAQ…).\n",
    "    2. `explore_database_schema` : inspecte la structure SQL (tables / colonnes).\n",
    "    3. `query_database` : exécute des requêtes SELECT (10 lignes max).\n",
    "\n",
    "    Stratégie recommandée\n",
    "    ---------------------\n",
    "    - Pour des questions métier (ventes, clients, stock) :\n",
    "      1. Commence par `explore_database_schema()` si tu n’es pas certain de la table.\n",
    "      2. Rédige UNE requête SQL complète, puis `query_database()`.\n",
    "      3. Reformule la réponse pour l’utilisateur (unités, sommes, ordres de grandeur).\n",
    "\n",
    "    - Pour de la documentation technique ou produit :\n",
    "      1. `search_documents()` avec des mots-clés précis.\n",
    "      2. Synthétise la réponse à partir des extraits retournés.\n",
    "\n",
    "    Règles\n",
    "    ------\n",
    "    - Utilise autant d’outils que nécessaire avant de répondre.\n",
    "    - Ne devine jamais un schéma SQL : vérifie-le.\n",
    "    - Garde un style concis et structuré (titres `###`, listes à puces, tableaux).\n",
    "\n",
    "    Autres règles relatives aux requêtes SQL:\n",
    "    1. **Un SEUL SQL principal** pour répondre : construis une requête agrégée complète (JOIN/CTE si besoin) au lieu de plusieurs petites requêtes indépendantes.\n",
    "    2. **Filtre de dates** : utilise des intervalles (`date >= 'YYYY-01-01' AND date < 'YYYY-02-01'`) au lieu de `MONTH()`/`YEAR()` (meilleure perf + index friendly).\n",
    "    3. **Auto-contrôle après exécution** :\n",
    "      - Si un champ agrégé ressort `NULL`, REFORMULE/REJOINS pour renvoyer 0 au lieu de NULL.\n",
    "      - Si le résultat paraît incohérent (ex: 10 commandes mais total NULL), relance une requête corrigée.\n",
    "    4. **Toujours afficher la requête exécutée** et le sens de chaque colonne retournée dans la réponse finale.\n",
    "    5. **Agrégations sûres** : enveloppe toute `SUM(...)` ou `COUNT(...)` susceptibles d’être vides dans `COALESCE(...,0)` pour éviter `NULL`.\n",
    "    §. SURTOUT ne devine jamais une table ou une colonne: vérifie\n",
    "    \"\"\"\n",
    "    msgs   = [HumanMessage(content=system)] + state[\"messages\"]\n",
    "    resp   = llm_tools.invoke(msgs)\n",
    "    return {\"messages\": state[\"messages\"] + [resp]}\n",
    "\n",
    "def should_continue(state: AgentState):\n",
    "    \"\"\"\n",
    "    Décide si le workflow LangGraph doit :\n",
    "\n",
    "    - exécuter les appels d’outils renvoyés par le LLM (“tools”)\n",
    "    - ou s’arrêter (END) et retourner la réponse finale à l’utilisateur.\n",
    "\n",
    "    Règle :\n",
    "    --------\n",
    "    Si le dernier message contient la clé `tool_calls` (c.-à-d. que le LLM\n",
    "    a demandé un ou plusieurs outils), on branche vers le nœud « tools ».\n",
    "    Sinon, on considère que la réponse est complète et on termine.\n",
    "    \"\"\"\n",
    "    last = state[\"messages\"][-1]\n",
    "    if getattr(last, \"tool_calls\", None):\n",
    "        return \"tools\"\n",
    "    return END\n",
    "\n",
    "graph = StateGraph(AgentState)\n",
    "graph.add_node(\"agent\", agent_node)\n",
    "graph.add_node(\"tools\", ToolNode([search_documents,\n",
    "                                  explore_database_schema,\n",
    "                                  query_database]))\n",
    "graph.set_entry_point(\"agent\")\n",
    "graph.add_conditional_edges(\"agent\", should_continue,\n",
    "                            {\"tools\": \"tools\", END: END})\n",
    "graph.add_edge(\"tools\", \"agent\")\n",
    "rag_agent = graph.compile()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gUxoXwENIjcV"
   },
   "source": [
    "Dernière étape : création d'une fonction pour dialoguer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gJ_u9jw-InoO"
   },
   "outputs": [],
   "source": [
    "def ask(question: str):\n",
    "    out = rag_agent.invoke({\"messages\": [HumanMessage(content=question)]})\n",
    "    return out[\"messages\"][-1].content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SvaHsJ3IIqPM"
   },
   "source": [
    "Exemples d'utilisations :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 426
    },
    "id": "QsOTKXX8IsLH",
    "outputId": "bf0f0bb1-4452-4ca9-8eae-d0ba7cd18315"
   },
   "outputs": [],
   "source": [
    "# Exemple 1: Requête dans la base de données\n",
    "ask(\"Combien de commandes avons-nous eu au mois de juillet et quelle est leur valeur totale?\")\n",
    "\n",
    "# Point à noter: il arrive que parfois l'agent n'arrive pas à calculer le montant et renvoie zéro euros\n",
    "# N'hésitez pas à relancer pour obtenir le résultat.\n",
    "# On touche ici aux limites d'un agent simple avec des tools limités\n",
    "# => La requête SQL formulée par le LLM n'est pas toujours correcte.\n",
    "# Typiquement pour cet exemple un workflow serait plus adapté\n",
    "# (la logique de sortir dans un premier temps le schéma et de bâtir la requête étant systématique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q_ij2_kNIr92"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cS-OfsufMbgr"
   },
   "source": [
    "## 🛠️ Tool tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YN4KWub6Mbgr"
   },
   "outputs": [],
   "source": [
    "# Classe pour tracker l'usage des outils\n",
    "class ToolUsageTracker:\n",
    "    def __init__(self):\n",
    "        self.tool_calls = []\n",
    "        self.session_start = datetime.now()\n",
    "\n",
    "    def track_tool_call(self, tool_name: str, args: dict, start_time: float, end_time: float,\n",
    "                       success: bool, result_summary: str = \"\", error: str = \"\"):\n",
    "        \"\"\"Enregistre l'utilisation d'un outil\"\"\"\n",
    "        self.tool_calls.append({\n",
    "            \"tool_name\": tool_name,\n",
    "            \"args\": args,\n",
    "            \"start_time\": datetime.fromtimestamp(start_time),\n",
    "            \"end_time\": datetime.fromtimestamp(end_time),\n",
    "            \"duration_ms\": round((end_time - start_time) * 1000, 2),\n",
    "            \"success\": success,\n",
    "            \"result_summary\": result_summary,\n",
    "            \"error\": error\n",
    "        })\n",
    "\n",
    "    def get_usage_summary(self):\n",
    "        \"\"\"Retourne un résumé de l'usage des outils\"\"\"\n",
    "        if not self.tool_calls:\n",
    "            return \"Aucun outil utilisé\"\n",
    "\n",
    "        summary = {\n",
    "            \"total_calls\": len(self.tool_calls),\n",
    "            \"total_duration_ms\": sum(call[\"duration_ms\"] for call in self.tool_calls),\n",
    "            \"success_rate\": len([c for c in self.tool_calls if c[\"success\"]]) / len(self.tool_calls) * 100,\n",
    "            \"tools_used\": list(set(call[\"tool_name\"] for call in self.tool_calls)),\n",
    "            \"calls_by_tool\": {}\n",
    "        }\n",
    "\n",
    "        for call in self.tool_calls:\n",
    "            tool = call[\"tool_name\"]\n",
    "            if tool not in summary[\"calls_by_tool\"]:\n",
    "                summary[\"calls_by_tool\"][tool] = {\n",
    "                    \"count\": 0,\n",
    "                    \"total_duration_ms\": 0,\n",
    "                    \"success_count\": 0\n",
    "                }\n",
    "\n",
    "            summary[\"calls_by_tool\"][tool][\"count\"] += 1\n",
    "            summary[\"calls_by_tool\"][tool][\"total_duration_ms\"] += call[\"duration_ms\"]\n",
    "            if call[\"success\"]:\n",
    "                summary[\"calls_by_tool\"][tool][\"success_count\"] += 1\n",
    "\n",
    "        return summary\n",
    "\n",
    "    def get_detailed_log(self):\n",
    "        \"\"\"Retourne le log détaillé des appels d'outils\"\"\"\n",
    "        return self.tool_calls\n",
    "\n",
    "# Instance globale du tracker\n",
    "tool_tracker = ToolUsageTracker()\n",
    "\n",
    "# Wrapper pour tracker les outils automatiquement\n",
    "def tracked_tool(func):\n",
    "    \"\"\"Décorateur pour tracker automatiquement l'usage des outils\"\"\"\n",
    "\n",
    "    @functools.wraps(func)\n",
    "    def wrapper(*args, **kwargs):\n",
    "        tool_name = func.__name__\n",
    "        start_time = time.time()\n",
    "\n",
    "        try:\n",
    "            result = func(*args, **kwargs)\n",
    "            end_time = time.time()\n",
    "\n",
    "            # Résumé du résultat (premiers 100 caractères)\n",
    "            result_summary = str(result)[:100] + \"...\" if len(str(result)) > 100 else str(result)\n",
    "\n",
    "            tool_tracker.track_tool_call(\n",
    "                tool_name=tool_name,\n",
    "                args={\"args\": args, \"kwargs\": kwargs},\n",
    "                start_time=start_time,\n",
    "                end_time=end_time,\n",
    "                success=True,\n",
    "                result_summary=result_summary\n",
    "            )\n",
    "\n",
    "            return result\n",
    "\n",
    "        except Exception as e:\n",
    "            end_time = time.time()\n",
    "\n",
    "            tool_tracker.track_tool_call(\n",
    "                tool_name=tool_name,\n",
    "                args={\"args\": args, \"kwargs\": kwargs},\n",
    "                start_time=start_time,\n",
    "                end_time=end_time,\n",
    "                success=False,\n",
    "                error=str(e)\n",
    "            )\n",
    "\n",
    "            raise e\n",
    "\n",
    "    return wrapper\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LvV89CxzMbgt"
   },
   "source": [
    "## 🔧 Configuration des Sources de Données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G3Km73QKMbgt"
   },
   "outputs": [],
   "source": [
    "\n",
    "try:\n",
    "    # Nouvelle API vectorielle\n",
    "    from azure.search.documents.models import VectorizedQuery\n",
    "    _HAS_VQ = True\n",
    "except ImportError:\n",
    "    _HAS_VQ = False\n",
    "\n",
    "# Cache global de l'embedder HuggingFace pour éviter de recharger à chaque appel\n",
    "_EMBED_MODEL = None\n",
    "\n",
    "def _get_embedder(model_name: str = \"sentence-transformers/all-MiniLM-L6-v2\"):\n",
    "    \"\"\"Charge une seule fois le modèle d'embedding HuggingFace.\"\"\"\n",
    "    global _EMBED_MODEL\n",
    "    if _EMBED_MODEL is None:\n",
    "        from sentence_transformers import SentenceTransformer\n",
    "        _EMBED_MODEL = SentenceTransformer(model_name)\n",
    "    return _EMBED_MODEL\n",
    "\n",
    "# Outils avec tracking automatique\n",
    "@tool\n",
    "@tracked_tool\n",
    "def search_documents(query: str, top_results: int = 3) -> str:\n",
    "    \"\"\"Recherche vectorielle (similarité cosinus) dans l'index Azure Search 'documents'.\n",
    "\n",
    "    On encode la requête avec le même modèle que celui utilisé pour indexer les embeddings,\n",
    "    puis on envoie une requête vectorielle à Azure Search. Résultats triés par proximité\n",
    "    (cosine / dot, selon la config de l'index HNSW).\n",
    "\n",
    "    Args:\n",
    "        query: Texte de la requête utilisateur.\n",
    "        top_results: Nombre maximum de résultats à retourner.\n",
    "\n",
    "    Returns:\n",
    "        Chaîne formatée en Markdown listant les meilleurs documents.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # --- Connexion Azure Search --------------------------------------------------\n",
    "        search_credential = AzureKeyCredential(config[\"search_key\"])\n",
    "        search_client = SearchClient(config[\"search_endpoint\"], \"documents\", search_credential)\n",
    "\n",
    "        # --- Embedding de la requête -------------------------------------------------\n",
    "        embedder = _get_embedder()  # charge/cashe le modèle HF\n",
    "        query_vec = embedder.encode(query)  # -> numpy array\n",
    "        # Azure attend une liste de floats (pas un np.ndarray)\n",
    "        query_vec = query_vec.tolist()\n",
    "\n",
    "        # --- Construction de la requête vectorielle ---------------------------------\n",
    "        if _HAS_VQ:\n",
    "            # Nouvelle API (>= 11.5 environ)\n",
    "            vq = VectorizedQuery(vector=query_vec, k=top_results, fields=\"embedding\")\n",
    "            results_iter = search_client.search(\n",
    "                search_text=\"*\",               # vector-only pattern\n",
    "                vector_queries=[vq],\n",
    "            )\n",
    "        else:\n",
    "            # Ancienne API (Vector)\n",
    "            from azure.search.documents.models import Vector\n",
    "            v = Vector(value=query_vec, k=top_results, fields=\"embedding\")\n",
    "            results_iter = search_client.search(\n",
    "                search_text=\"*\",\n",
    "                vector=v,\n",
    "            )\n",
    "\n",
    "        # --- Collecte & formatage ----------------------------------------------------\n",
    "        results = list(results_iter)\n",
    "        if not results:\n",
    "            return f\"Aucun document trouvé (vector search) pour '{query}'.\"\n",
    "\n",
    "        formatted_results = []\n",
    "        for i, result in enumerate(results, 1):\n",
    "            # result est SearchResult dict-like\n",
    "            filename = result.get(\"filename\", \"N/A\")\n",
    "            doc_type = result.get(\"type\", \"N/A\")\n",
    "            content_preview = (result.get(\"content\", \"\") or \"\")[:200] + \"...\"\n",
    "            score = result.get(\"@search.score\", 0)\n",
    "\n",
    "            formatted_results.append(\n",
    "                f\"**Document {i}: {filename}** *(type: {doc_type}, score: {score:.4f})*\\n\"\n",
    "                f\"{content_preview}\\n\"\n",
    "            )\n",
    "\n",
    "        return \"\\n\".join(formatted_results)\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"Erreur recherche vectorielle documents: {str(e)}\"\n",
    "\n",
    "\n",
    "@tool\n",
    "@tracked_tool\n",
    "def query_database(sql_query: str) -> str:\n",
    "    \"\"\"Exécute une requête SQL sur la base de données VéloCorp.\n",
    "\n",
    "    Args:\n",
    "        sql_query: Requête SQL à exécuter (SELECT uniquement)\n",
    "\n",
    "    Returns:\n",
    "        Résultats de la requête formatés\n",
    "\n",
    "    Note: Si la requête échoue à cause d'une table/colonne inconnue,\n",
    "    utilise explore_database_schema() pour voir la structure.\n",
    "    \"\"\"\n",
    "    # Vérification de sécurité - uniquement SELECT\n",
    "    if not sql_query.strip().upper().startswith('SELECT'):\n",
    "        return \"❌ Erreur: Seules les requêtes SELECT sont autorisées\"\n",
    "\n",
    "    try:\n",
    "        connection_string = f\"DRIVER={{ODBC Driver 18 for SQL Server}};SERVER={config['sql_server']};DATABASE={config['sql_database']};UID={config['sql_username']};PWD={config['sql_password']};Encrypt=yes;TrustServerCertificate=no;Connection Timeout=30;\"\n",
    "\n",
    "        with pyodbc.connect(connection_string) as conn:\n",
    "            cursor = conn.cursor()\n",
    "            cursor.execute(sql_query)\n",
    "\n",
    "            # Récupération des colonnes\n",
    "            columns = [desc[0] for desc in cursor.description]\n",
    "            rows = cursor.fetchall()\n",
    "\n",
    "            if not rows:\n",
    "                return \"ℹ️ Aucun résultat trouvé pour cette requête\"\n",
    "\n",
    "            # Formatage des résultats\n",
    "            result_lines = [\" | \".join(columns)]\n",
    "            result_lines.append(\"-\" * len(result_lines[0]))\n",
    "\n",
    "            for row in rows[:10]:  # Limite à 10 résultats\n",
    "                formatted_row = []\n",
    "                for val in row:\n",
    "                    if val is None:\n",
    "                        formatted_row.append(\"NULL\")\n",
    "                    else:\n",
    "                        formatted_row.append(str(val)[:50])  # Limite à 50 chars\n",
    "                result_lines.append(\" | \".join(formatted_row))\n",
    "\n",
    "            if len(rows) > 10:\n",
    "                result_lines.append(f\"... et {len(rows) - 10} autres résultats\")\n",
    "\n",
    "            # Ajout d'informations contextuelles\n",
    "            result = \"\\n\".join(result_lines)\n",
    "            result += f\"\\n\\n✅ **{len(rows)} résultat(s) trouvé(s)**\"\n",
    "\n",
    "            return result\n",
    "\n",
    "    except Exception as e:\n",
    "        error_msg = str(e).lower()\n",
    "\n",
    "        # Messages d'erreur intelligents avec suggestions\n",
    "        if \"invalid object name\" in error_msg or \"invalid column name\" in error_msg:\n",
    "            suggestion = \"\\n\\n💡 **Suggestion**: La table ou colonne semble inexistante. \"\n",
    "            suggestion += \"Utilise explore_database_schema() pour voir les tables disponibles, \"\n",
    "            suggestion += \"ou explore_database_schema('nom_table') pour voir la structure d'une table.\"\n",
    "            return f\"❌ Erreur SQL: {str(e)}{suggestion}\"\n",
    "\n",
    "        elif \"syntax error\" in error_msg:\n",
    "            suggestion = \"\\n\\n💡 **Suggestion**: Erreur de syntaxe SQL. \"\n",
    "            suggestion += \"Utilise get_sql_examples() pour voir des exemples de requêtes.\"\n",
    "            return f\"❌ Erreur de syntaxe: {str(e)}{suggestion}\"\n",
    "\n",
    "        elif \"permission\" in error_msg or \"access\" in error_msg:\n",
    "            return f\"❌ Erreur de permissions: {str(e)}\\nSeules les requêtes SELECT sont autorisées.\"\n",
    "\n",
    "        else:\n",
    "            return f\"❌ Erreur base de données: {str(e)}\"\n",
    "\n",
    "@tool\n",
    "@tracked_tool\n",
    "def query_crm_api(endpoint: str, params: dict = None) -> str:\n",
    "    \"\"\"Interroge l'API CRM VéloCorp.\n",
    "\n",
    "    Args:\n",
    "        endpoint: Endpoint à appeler (commerciaux, prospects, opportunites, analytics)\n",
    "        params: Paramètres optionnels de la requête\n",
    "\n",
    "    Returns:\n",
    "        Réponse de l'API formatée\n",
    "    \"\"\"\n",
    "    try:\n",
    "        url = f\"{config['api_base_url']}/crm/{endpoint}\"\n",
    "\n",
    "        response = requests.get(url, params=params or {}, timeout=30)\n",
    "        response.raise_for_status()\n",
    "\n",
    "        data = response.json()\n",
    "\n",
    "        # Formatage selon l'endpoint\n",
    "        if endpoint == \"commerciaux\":\n",
    "            commerciaux = data.get('commerciaux', [])\n",
    "            result = f\"**{data.get('count', 0)} commerciaux trouvés:**\\n\"\n",
    "            for com in commerciaux[:5]:\n",
    "                result += f\"- {com['name']} ({com['email']}) - Régions: {', '.join(com['assigned_regions'])}\\n\"\n",
    "            return result\n",
    "\n",
    "        elif endpoint == \"prospects\":\n",
    "            prospects = data.get('prospects', [])\n",
    "            resume = data.get('resume', {})\n",
    "            result = f\"**{data.get('count', 0)} prospects trouvés:**\\n\"\n",
    "            result += f\"Score moyen: {resume.get('score_moyen', 0)}\\n\"\n",
    "            for prospect in prospects[:3]:\n",
    "                result += f\"- {prospect['contact_name']} ({prospect['company']}) - Score: {prospect['lead_score']}\\n\"\n",
    "            return result\n",
    "\n",
    "        elif endpoint == \"opportunites\":\n",
    "            opportunites = data.get('opportunites', [])\n",
    "            metriques = data.get('metriques_pipeline', {})\n",
    "            result = f\"**{data.get('count', 0)} opportunités trouvées:**\\n\"\n",
    "            result += f\"Valeur pipeline: {metriques.get('valeur_pipeline', 0):,.2f}€\\n\"\n",
    "            for opp in opportunites[:3]:\n",
    "                result += f\"- {opp['title']} - {opp['estimated_value']:,.2f}€ ({opp['status']})\\n\"\n",
    "            return result\n",
    "\n",
    "        elif endpoint == \"analytics\":\n",
    "            globales = data.get('metriques_globales', {})\n",
    "            result = \"**Analytics CRM:**\\n\"\n",
    "            result += f\"Total prospects: {globales.get('total_prospects', 0)}\\n\"\n",
    "            result += f\"Total opportunités: {globales.get('total_opportunites', 0)}\\n\"\n",
    "            result += f\"Valeur pipeline: {globales.get('valeur_pipeline', 0):,.2f}€\\n\"\n",
    "            result += f\"Valeur gagnée: {globales.get('valeur_gagnee', 0):,.2f}€\\n\"\n",
    "            return result\n",
    "\n",
    "        else:\n",
    "            return json.dumps(data, indent=2, ensure_ascii=False)[:500] + \"...\"\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"Erreur API CRM: {str(e)}\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a4XNKfzmMbgw"
   },
   "outputs": [],
   "source": [
    "@tool\n",
    "@tracked_tool\n",
    "def explore_database_schema(table_name: str = None) -> str:\n",
    "    \"\"\"Explore le schéma de la base de données VéloCorp.\n",
    "\n",
    "    Args:\n",
    "        table_name: Nom de la table à explorer (optionnel, si vide retourne toutes les tables)\n",
    "\n",
    "    Returns:\n",
    "        Structure des tables et colonnes\n",
    "    \"\"\"\n",
    "    try:\n",
    "        connection_string = f\"DRIVER={{ODBC Driver 18 for SQL Server}};SERVER={config['sql_server']};DATABASE={config['sql_database']};UID={config['sql_username']};PWD={config['sql_password']};Encrypt=yes;TrustServerCertificate=no;Connection Timeout=30;\"\n",
    "\n",
    "        with pyodbc.connect(connection_string) as conn:\n",
    "            cursor = conn.cursor()\n",
    "\n",
    "            if table_name:\n",
    "                # Exploration d'une table spécifique\n",
    "                query = \"\"\"\n",
    "                SELECT\n",
    "                    c.COLUMN_NAME,\n",
    "                    c.DATA_TYPE,\n",
    "                    c.IS_NULLABLE,\n",
    "                    c.COLUMN_DEFAULT,\n",
    "                    CASE WHEN pk.COLUMN_NAME IS NOT NULL THEN 'PK' ELSE '' END as IS_PRIMARY_KEY,\n",
    "                    CASE WHEN fk.COLUMN_NAME IS NOT NULL THEN\n",
    "                        'FK -> ' + fk.REFERENCED_TABLE_NAME + '(' + fk.REFERENCED_COLUMN_NAME + ')'\n",
    "                    ELSE '' END as FOREIGN_KEY\n",
    "                FROM INFORMATION_SCHEMA.COLUMNS c\n",
    "                LEFT JOIN (\n",
    "                    SELECT ku.TABLE_NAME, ku.COLUMN_NAME\n",
    "                    FROM INFORMATION_SCHEMA.TABLE_CONSTRAINTS tc\n",
    "                    JOIN INFORMATION_SCHEMA.KEY_COLUMN_USAGE ku\n",
    "                        ON tc.CONSTRAINT_NAME = ku.CONSTRAINT_NAME\n",
    "                    WHERE tc.CONSTRAINT_TYPE = 'PRIMARY KEY'\n",
    "                ) pk ON c.TABLE_NAME = pk.TABLE_NAME AND c.COLUMN_NAME = pk.COLUMN_NAME\n",
    "                LEFT JOIN (\n",
    "                    SELECT\n",
    "                        ku.TABLE_NAME, ku.COLUMN_NAME,\n",
    "                        ku2.TABLE_NAME as REFERENCED_TABLE_NAME,\n",
    "                        ku2.COLUMN_NAME as REFERENCED_COLUMN_NAME\n",
    "                    FROM INFORMATION_SCHEMA.REFERENTIAL_CONSTRAINTS rc\n",
    "                    JOIN INFORMATION_SCHEMA.KEY_COLUMN_USAGE ku\n",
    "                        ON rc.CONSTRAINT_NAME = ku.CONSTRAINT_NAME\n",
    "                    JOIN INFORMATION_SCHEMA.KEY_COLUMN_USAGE ku2\n",
    "                        ON rc.UNIQUE_CONSTRAINT_NAME = ku2.CONSTRAINT_NAME\n",
    "                ) fk ON c.TABLE_NAME = fk.TABLE_NAME AND c.COLUMN_NAME = fk.COLUMN_NAME\n",
    "                WHERE c.TABLE_NAME = ?\n",
    "                ORDER BY c.ORDINAL_POSITION\n",
    "                \"\"\"\n",
    "                cursor.execute(query, table_name)\n",
    "                columns = cursor.fetchall()\n",
    "\n",
    "                if not columns:\n",
    "                    return f\"Table '{table_name}' non trouvée\"\n",
    "\n",
    "                result = f\"**Structure de la table {table_name}:**\\n\"\n",
    "                result += \"| Colonne | Type | Nullable | Défaut | Clé |\\n\"\n",
    "                result += \"|---------|------|----------|--------|-----|\\n\"\n",
    "\n",
    "                for col in columns:\n",
    "                    key_info = f\"{col[4]} {col[5]}\".strip()\n",
    "                    result += f\"| {col[0]} | {col[1]} | {col[2]} | {col[3] or 'NULL'} | {key_info} |\\n\"\n",
    "\n",
    "                # Ajouter un échantillon de données\n",
    "                sample_query = f\"SELECT TOP 3 * FROM {table_name}\"\n",
    "                cursor.execute(sample_query)\n",
    "                sample_data = cursor.fetchall()\n",
    "\n",
    "                if sample_data:\n",
    "                    result += f\"\\n**Échantillon de données:**\\n\"\n",
    "                    column_names = [desc[0] for desc in cursor.description]\n",
    "                    result += \" | \".join(column_names) + \"\\n\"\n",
    "                    result += \"-\" * len(\" | \".join(column_names)) + \"\\n\"\n",
    "\n",
    "                    for row in sample_data:\n",
    "                        formatted_row = [str(val) if val is not None else 'NULL' for val in row]\n",
    "                        result += \" | \".join(formatted_row) + \"\\n\"\n",
    "\n",
    "                return result\n",
    "\n",
    "            else:\n",
    "                # Liste de toutes les tables\n",
    "                query = \"\"\"\n",
    "                SELECT\n",
    "                    t.TABLE_NAME,\n",
    "                    COUNT(c.COLUMN_NAME) as COLUMN_COUNT,\n",
    "                    STRING_AGG(c.COLUMN_NAME, ', ') as COLUMNS\n",
    "                FROM INFORMATION_SCHEMA.TABLES t\n",
    "                LEFT JOIN INFORMATION_SCHEMA.COLUMNS c ON t.TABLE_NAME = c.TABLE_NAME\n",
    "                WHERE t.TABLE_TYPE = 'BASE TABLE'\n",
    "                GROUP BY t.TABLE_NAME\n",
    "                ORDER BY t.TABLE_NAME\n",
    "                \"\"\"\n",
    "                cursor.execute(query)\n",
    "                tables = cursor.fetchall()\n",
    "\n",
    "                result = \"**Tables disponibles dans la base VéloCorp:**\\n\"\n",
    "                for table in tables:\n",
    "                    result += f\"- **{table[0]}** ({table[1]} colonnes)\\n\"\n",
    "                    if table[2]:\n",
    "                        columns_preview = table[2][:100] + \"...\" if len(table[2]) > 100 else table[2]\n",
    "                        result += f\"  Colonnes: {columns_preview}\\n\"\n",
    "\n",
    "                result += \"\\nUtilise explore_database_schema('nom_table') pour plus de détails sur une table spécifique.\"\n",
    "                return result\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"Erreur exploration schéma: {str(e)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OZB_opaQMbgy",
    "outputId": "7e112a43-e1c9-48ee-9239-697fded55670"
   },
   "outputs": [],
   "source": [
    "# Liste des outils disponibles\n",
    "tools = [search_documents, query_database, query_crm_api, explore_database_schema]\n",
    "\n",
    "# LLM avec outils\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "# État du graphe\n",
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "def agent_node(state: AgentState):\n",
    "    \"\"\"Nœud principal de l'agent avec instructions détaillées pour la DB\"\"\"\n",
    "    system_prompt = \"\"\"\n",
    "    Tu es un assistant intelligent pour VéloCorp, entreprise de vélos.\n",
    "    Tu as accès à 5 outils spécialisés :\n",
    "\n",
    "    ## 🔍 OUTILS DISPONIBLES:\n",
    "\n",
    "    1. **explore_database_schema()** - Explorer la structure de la DB\n",
    "       - Sans paramètre : liste toutes les tables\n",
    "       - Avec nom_table : détails d'une table spécifique\n",
    "\n",
    "    2. **get_sql_examples(category)** - Exemples de requêtes SQL\n",
    "       - Catégories : clients, commandes, produits, analytics, all\n",
    "\n",
    "    3. **query_database(sql_query)** - Exécuter des requêtes SQL\n",
    "       - Uniquement SELECT autorisé\n",
    "       - Messages d'erreur intelligents avec suggestions\n",
    "\n",
    "    4. **search_documents(query)** - Rechercher dans la documentation\n",
    "       - Manuels, FAQ, emails internes\n",
    "\n",
    "    5. **query_crm_api(endpoint)** - API CRM\n",
    "       - Endpoints : commerciaux, prospects, opportunites, analytics\n",
    "\n",
    "    ##### 🎯 STRATÉGIE OPTIMALE:\n",
    "\n",
    "    ### STRATÉGIE OUTILS\n",
    "\n",
    "    - Étape 1 : `explore_database_schema()` (global puis tables candidates).\n",
    "    - Étape 2 : Génère la requête SQL complète → `query_database()`.\n",
    "    - Étape 3 : Si résultat incomplet/NULL, corrige et relance (ne PAS répondre tant que les 2 métriques demandées ne sont pas numériques).\n",
    "\n",
    "    Autres règles relatives aux requêtes SQL:\n",
    "    1. **Un SEUL SQL principal** pour répondre : construis une requête agrégée complète (JOIN/CTE si besoin) au lieu de plusieurs petites requêtes indépendantes.\n",
    "    2. **Toujours vérifier le schéma avant d’écrire du SQL** avec `explore_database_schema()` et résumer mentalement:\n",
    "      - quelles tables contiennent les commandes ?\n",
    "      - où se trouve le montant (orders.total ? order_items.unit_price*quantity ? invoices.amount ?).\n",
    "    3. **Filtre de dates** : utilise des intervalles (`date >= 'YYYY-01-01' AND date < 'YYYY-02-01'`) au lieu de `MONTH()`/`YEAR()` (meilleure perf + index friendly).\n",
    "    4. **Agrégations sûres** : enveloppe toute `SUM(...)` ou `COUNT(...)` susceptibles d’être vides dans `COALESCE(...,0)` pour éviter `NULL`.\n",
    "    5. **Préserver le comptage des commandes même sans facture** : utilise des `LEFT JOIN` depuis `orders` vers les autres tables.\n",
    "    6. **Auto-contrôle après exécution** :\n",
    "      - Si un champ agrégé ressort `NULL`, REFORMULE/REJOINS pour renvoyer 0 au lieu de NULL.\n",
    "      - Si le résultat paraît incohérent (ex: 10 commandes mais total NULL), relance une requête corrigée.\n",
    "    7. **Toujours afficher la requête exécutée** et le sens de chaque colonne retournée dans la réponse finale.\n",
    "    8. **Ne pas confondre “valeur des commandes” et “montant facturé”** :\n",
    "      - si la question dit “valeur des commandes”, calcule à partir d’`orders` ou `order_items`; les factures ne sont qu’un proxy éventuel.\n",
    "\n",
    "    Respecte ces règles avant de répondre.\n",
    "\n",
    "    **Pour les questions sur la base de données :**\n",
    "    1. 🔍 **TOUJOURS commencer par explore_database_schema()** si tu ne connais pas la structure exacte\n",
    "    2. 📚 Si besoin d'inspiration pour les requêtes → get_sql_examples()\n",
    "    3. ⚡ Puis exécuter → query_database()\n",
    "\n",
    "    **Exemples de workflow :**\n",
    "    - \"Nos meilleurs clients\" → explore_database_schema('clients') → query_database(...)\n",
    "    - \"Ventes du mois\" → explore_database_schema('commandes') → query_database(...)\n",
    "    - \"Stock vélos\" → explore_database_schema('produits') → query_database(...)\n",
    "\n",
    "    **Pour autres types de questions :**\n",
    "    - Documentation/FAQ → search_documents()\n",
    "    - Performance commerciale → query_crm_api()\n",
    "\n",
    "    ## ⚡ RÈGLES IMPORTANTES:\n",
    "    - Ne devines JAMAIS la structure des tables\n",
    "    - Utilise explore_database_schema() avant toute requête SQL complexe\n",
    "    - Sois précis et concis dans tes réponses\n",
    "    - Priorise la qualité des données sur la rapidité\n",
    "\n",
    "    **Tu es maintenant prêt à aider efficacement avec VéloCorp !** 🚴‍♂️\n",
    "    \"\"\"\n",
    "\n",
    "    '''\n",
    "    messages = [HumanMessage(content=system_prompt)] + state[\"messages\"]\n",
    "    print(\"Prompt envoyé au LLM avec outils:\", messages)\n",
    "    response = llm_with_tools.invoke(messages)\n",
    "    print(\"réponse brute du LLM\")\n",
    "    return {\"messages\": [response]}\n",
    "    '''\n",
    "    messages = [HumanMessage(content=system_prompt)] + state[\"messages\"]\n",
    "    response = llm_with_tools.invoke(messages)\n",
    "    return {\"messages\": state[\"messages\"] + [response]}\n",
    "\n",
    "\n",
    "# Fonction de routage\n",
    "def should_continue(state: AgentState):\n",
    "    \"\"\"Détermine si on continue ou on termine\"\"\"\n",
    "    print(\"Check du should_continue, messages actuels :\", state[\"messages\"])\n",
    "\n",
    "    last_message = state[\"messages\"][-1]\n",
    "    if hasattr(last_message, 'tool_calls') and last_message.tool_calls:\n",
    "        return \"tools\"\n",
    "    print(\"On termine l'agent.\")\n",
    "\n",
    "    return END\n",
    "\n",
    "# Construction du graphe\n",
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "# Ajout des nœuds\n",
    "print(\"Ajout du noeud agent\")\n",
    "workflow.add_node(\"agent\", agent_node)\n",
    "print(\"Ajout du noeud tools\")\n",
    "workflow.add_node(\"tools\", ToolNode(tools))\n",
    "\n",
    "# Définition des edges\n",
    "workflow.set_entry_point(\"agent\")\n",
    "workflow.add_conditional_edges(\n",
    "    \"agent\",\n",
    "    should_continue,\n",
    "    {\n",
    "        \"tools\": \"tools\",\n",
    "        END: END\n",
    "    }\n",
    ")\n",
    "workflow.add_edge(\"tools\", \"agent\")\n",
    "\n",
    "# Compilation du graphe\n",
    "app = workflow.compile()\n",
    "print(\"🤖 Agent LangGraph créé avec succès!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V0NAOYCXMbgy"
   },
   "source": [
    "## 🤖 Création de l'Agent LangGraph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-B-2WQ13Mbgz"
   },
   "source": [
    "## 🎯 Fonction d'Interaction Simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "98VIrpknMbgz"
   },
   "outputs": [],
   "source": [
    "def ask_agent(\n",
    "    question: str,\n",
    "    verbose: bool = True,\n",
    "    show_tool_details: bool = False,\n",
    "    show_usage_stats: bool = False\n",
    "):\n",
    "    \"\"\"\n",
    "    Pose une question à l'agent et affiche la réponse avec options de diagnostic\n",
    "    \"\"\"\n",
    "    print(\"\\n❓ **Question:**\", question)\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "    # Reset du tracker pour cette question\n",
    "    global tool_tracker\n",
    "    tool_tracker = ToolUsageTracker()\n",
    "\n",
    "    try:\n",
    "        print(\"[DEBUG] Début exécution agent...\")\n",
    "        start_time = time.time()\n",
    "\n",
    "        # ENVOI DE LA QUESTION À L'AGENT\n",
    "        result = app.invoke({\"messages\": [HumanMessage(content=question)]})\n",
    "\n",
    "        end_time = time.time()\n",
    "        print(\"[DEBUG] Résultat brut de l'agent :\")\n",
    "        print(result)\n",
    "\n",
    "        # TEST CLÉ: Y A-T-IL BIEN UN CHAMP 'messages' ?\n",
    "        if \"messages\" not in result:\n",
    "            print(\"[DEBUG] Pas de clé 'messages' dans le résultat !\")\n",
    "            return\n",
    "\n",
    "        print(\"[DEBUG] Messages retournés :\")\n",
    "        print(result[\"messages\"])\n",
    "\n",
    "        # On prend le dernier message\n",
    "        last_message = result[\"messages\"][-1]\n",
    "        print(\"[DEBUG] Dernier message :\")\n",
    "        print(last_message)\n",
    "\n",
    "        # REGARDE LE CHAMP content\n",
    "        if hasattr(last_message, 'content'):\n",
    "            final_response = last_message.content\n",
    "        elif isinstance(last_message, dict) and \"content\" in last_message:\n",
    "            final_response = last_message[\"content\"]\n",
    "        else:\n",
    "            print(\"[DEBUG] Aucun champ 'content' trouvé dans le dernier message.\")\n",
    "            final_response = \"\"\n",
    "\n",
    "        print(f\"🤖 **Réponse:** {final_response}\")\n",
    "\n",
    "        # Affichage du temps total\n",
    "        total_time = round((end_time - start_time) * 1000, 2)\n",
    "        print(f\"\\n⏱️ **Temps total:** {total_time}ms\")\n",
    "\n",
    "        # Reste de la logique (outils/diagnostic)\n",
    "        if verbose or show_tool_details or show_usage_stats:\n",
    "            usage_summary = tool_tracker.get_usage_summary()\n",
    "\n",
    "            if verbose and usage_summary != \"Aucun outil utilisé\":\n",
    "                print(f\"\\n🔧 **Outils utilisés:** {', '.join(usage_summary['tools_used'])}\")\n",
    "                print(f\"📊 **Nombre d'appels:** {usage_summary['total_calls']}\")\n",
    "                print(f\"✅ **Taux de succès:** {usage_summary['success_rate']:.1f}%\")\n",
    "\n",
    "            if show_usage_stats and usage_summary != \"Aucun outil utilisé\":\n",
    "                print(f\"\\n📈 **Statistiques détaillées:**\")\n",
    "                print(f\"   - Temps total outils: {usage_summary['total_duration_ms']}ms\")\n",
    "\n",
    "                for tool_name, stats in usage_summary['calls_by_tool'].items():\n",
    "                    success_rate = (stats['success_count'] / stats['count']) * 100\n",
    "                    avg_time = stats['total_duration_ms'] / stats['count']\n",
    "                    print(f\"   - {tool_name}: {stats['count']} appels, {avg_time:.1f}ms moyen, {success_rate:.1f}% succès\")\n",
    "\n",
    "            if show_tool_details and usage_summary != \"Aucun outil utilisé\":\n",
    "                print(f\"\\n🔍 **Détails des appels d'outils:**\")\n",
    "                for i, call in enumerate(tool_tracker.get_detailed_log(), 1):\n",
    "                    status = \"✅\" if call['success'] else \"❌\"\n",
    "                    print(f\"   {i}. {status} {call['tool_name']} ({call['duration_ms']}ms)\")\n",
    "                    if call['args']['kwargs']:\n",
    "                        print(f\"      Args: {call['args']['kwargs']}\")\n",
    "                    if not call['success']:\n",
    "                        print(f\"      Erreur: {call['error']}\")\n",
    "                    elif call['result_summary']:\n",
    "                        print(f\"      Résultat: {call['result_summary']}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ **Erreur:** {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "    print(\"\\n\" + \"=\"*70)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UMAviQC2ye89"
   },
   "source": [
    "### Illustration des retours du tool \"explore_database_schema\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5dSc1ynCMbg0",
    "outputId": "8d1a1162-f66c-4221-d39d-4fe0c65c9d48"
   },
   "outputs": [],
   "source": [
    "print(explore_database_schema.invoke({}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4V1O9An6Mbg1",
    "outputId": "d07aa50c-8ca9-45dc-cf1c-0d6719dea1cb"
   },
   "outputs": [],
   "source": [
    "print(explore_database_schema('customers'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xR8xwOjlyt3j"
   },
   "source": [
    "### Illustration du retour du Tool \"query_api_crm\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YDR8v6EhMbg1",
    "outputId": "0b69d067-200a-43ba-ce89-cc1c023aff27"
   },
   "outputs": [],
   "source": [
    "print(query_crm_api(\"commerciaux\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8lp60ODRMbg1"
   },
   "source": [
    "# Exemples d'Interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 495
    },
    "id": "McZLKUa8Mbg2",
    "outputId": "bf73ed8c-2d5e-4db4-9c0f-c8544938fbce"
   },
   "outputs": [],
   "source": [
    "# Exemple 1: Requête dans la base de données\n",
    "ask_agent(\"Combien de commandes avons-nous eu au mois de janvier et quelle est leur valeur totale?\")\n",
    "\n",
    "# Point à noter: il arrive que parfois l'agent n'arrive pas à calculer le montant et renvoie zéro euros\n",
    "# N'hésitez pas à relancer pour obtenir le résultat.\n",
    "# On touche ici aux limites d'un agent simple avec des tools limités\n",
    "# => La requête SQL formulée par le LLM n'est pas toujours correcte.\n",
    "# Typiquement pour cet exemple un workflow serait plus adapté\n",
    "# (la logique de sortir dans un premier temps le schéma et de bâtir la requête étant systématique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nMawniPKMbg2"
   },
   "outputs": [],
   "source": [
    "# Exemple 2 : recherche vectorielle et CRM\n",
    "ask_agent(\n",
    "    question=\"Dans quelles couleurs est disponible le vélo urbain-confort et quels sont ses clients potentiels ?\",\n",
    "    verbose=True,\n",
    "    show_tool_details=True,\n",
    "    show_usage_stats=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ToDLwn6cMbg2"
   },
   "outputs": [],
   "source": [
    "# Exemple 3: API CRM\n",
    "ask_agent(\"Qui sont nos meilleurs clients et combien ont ils dépensé ?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DrfhL7rMMbg3"
   },
   "outputs": [],
   "source": [
    "# Exemple 3: API CRM\n",
    "ask_agent(\n",
    "    question=\"Qui sont nos meilleurs commerciaux et quelles sont leurs performances?\",\n",
    "    verbose=True,\n",
    "    show_tool_details=True,\n",
    "    show_usage_stats=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YdP2OjtXMbg3"
   },
   "outputs": [],
   "source": [
    "# Exemple 4: Question complexe nécessitant plusieurs sources\n",
    "ask_agent(\"Quels sont nos produits les plus vendus et y a-t-il des opportunités commerciales en cours pour ces modèles?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tBcq03CnMbg3"
   },
   "outputs": [],
   "source": [
    "# Exemple 4: Question complexe nécessitant plusieurs sources\n",
    "ask_agent(\"Quels sont nos produits les plus vendus et y a-t-il des opportunités commerciales en cours pour ces modèles?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bQQlBiumMbg3"
   },
   "outputs": [],
   "source": [
    "# Exemple 4: Question complexe nécessitant plusieurs sources\n",
    "ask_agent(\"Quels sont nos produits les plus vendus et y a-t-il des opportunités commerciales en cours pour ces modèles?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LoEKRIO11Yxn"
   },
   "outputs": [],
   "source": [
    "# =======================================================================\n",
    "#  Streamlit Chatbot VéloCorp – 100 % autonome dans UNE cellule\n",
    "# =======================================================================\n",
    "#\n",
    "#  ⚠️  Prérequis (à installer une seule fois)\n",
    "#  ------------------------------------------------\n",
    "#  pip install streamlit langchain langgraph azure-search-documents \\\n",
    "#              sentence-transformers pyodbc requests\n",
    "#\n",
    "#  ⚙️  Variables d’environnement attendues\n",
    "#  ------------------------------------------------\n",
    "#  OPENAI_API_KEY          = <clé Azure OpenAI>\n",
    "#  OPENAI_ENDPOINT         = <https://...>.openai.azure.com\n",
    "#  OPENAI_DEPLOYMENT       = <nom du déploiement chat>\n",
    "#  OPENAI_API_VERSION      = 2024-02-15-preview\n",
    "#\n",
    "#  SEARCH_ENDPOINT         = https://....search.windows.net\n",
    "#  SEARCH_KEY              = <clé Admin ou Query>\n",
    "#\n",
    "#  SQL_SERVER              = <host.database.windows.net>\n",
    "#  SQL_DATABASE            = <nom BDD>\n",
    "#  SQL_USERNAME            = <login SQL>\n",
    "#  SQL_PASSWORD            = <password>\n",
    "#\n",
    "#  API_BASE_URL            = https://api.velocorp.com\n",
    "#\n",
    "#  ➜ Adaptez si besoin, ou remplacez les os.getenv(...) ci-dessous par\n",
    "#    des chaînes “en dur” pour un test rapide.\n",
    "# -----------------------------------------------------------------------\n",
    "import streamlit as st\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# 📋 Configuration (chargée depuis les variables d’environnement)\n",
    "# ----------------------------------------------------------------------\n",
    "config: Dict[str, str] = {\n",
    "    \"openai_key\":        os.getenv(\"OPENAI_API_KEY\"),\n",
    "    \"openai_endpoint\":   os.getenv(\"OPENAI_ENDPOINT\"),\n",
    "    \"chat_deployment\":   os.getenv(\"OPENAI_DEPLOYMENT\"),\n",
    "    \"openai_version\":    os.getenv(\"OPENAI_API_VERSION\", \"2024-02-15-preview\"),\n",
    "    \"search_endpoint\":   os.getenv(\"SEARCH_ENDPOINT\"),\n",
    "    \"search_key\":        os.getenv(\"SEARCH_KEY\"),\n",
    "    \"sql_server\":        os.getenv(\"SQL_SERVER\"),\n",
    "    \"sql_database\":      os.getenv(\"SQL_DATABASE\"),\n",
    "    \"sql_username\":      os.getenv(\"SQL_USERNAME\"),\n",
    "    \"sql_password\":      os.getenv(\"SQL_PASSWORD\"),\n",
    "    \"api_base_url\":      os.getenv(\"API_BASE_URL\"),\n",
    "}\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# 🔧 Utilitaires & classes déjà fournis plus haut (inchangés)\n",
    "#    ⬇️  Copiés/collés tels quels pour être self-contained\n",
    "# ----------------------------------------------------------------------\n",
    "\n",
    "logging.basicConfig(level=logging.INFO,\n",
    "                    format=\"%(asctime)s [%(levelname)s] %(message)s\")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# ---------- Embeddings cache -------------------------------------------------\n",
    "_EMBED_MODEL = None\n",
    "def _get_embedder(model_name: str = \"sentence-transformers/all-MiniLM-L6-v2\"):\n",
    "    global _EMBED_MODEL\n",
    "    if _EMBED_MODEL is None:\n",
    "        from sentence_transformers import SentenceTransformer\n",
    "        _EMBED_MODEL = SentenceTransformer(model_name)\n",
    "    return _EMBED_MODEL\n",
    "\n",
    "# ---------- Tracker ----------------------------------------------------------\n",
    "class ToolUsageTracker:\n",
    "    def __init__(self): self.reset()\n",
    "    def reset(self):\n",
    "        self.tool_calls = []\n",
    "        self.session_start = datetime.now()\n",
    "    def track_tool_call(self, tool_name: str, args: dict,\n",
    "                        start_time: float, end_time: float,\n",
    "                        success: bool, result_summary: str = \"\", error: str = \"\"):\n",
    "        self.tool_calls.append({\n",
    "            \"tool_name\": tool_name,\n",
    "            \"args\": args,\n",
    "            \"start_time\": datetime.fromtimestamp(start_time),\n",
    "            \"end_time\": datetime.fromtimestamp(end_time),\n",
    "            \"duration_ms\": round((end_time - start_time) * 1000, 2),\n",
    "            \"success\": success,\n",
    "            \"result_summary\": result_summary,\n",
    "            \"error\": error\n",
    "        })\n",
    "    def get_usage_summary(self):\n",
    "        if not self.tool_calls: return \"Aucun outil utilisé\"\n",
    "        s = {\n",
    "            \"total_calls\": len(self.tool_calls),\n",
    "            \"total_duration_ms\": sum(c[\"duration_ms\"] for c in self.tool_calls),\n",
    "            \"tools_used\": list({c[\"tool_name\"] for c in self.tool_calls}),\n",
    "        }\n",
    "        return s\n",
    "tool_tracker = ToolUsageTracker()\n",
    "\n",
    "def tracked_tool(func):\n",
    "    @functools.wraps(func)\n",
    "    def wrapper(*args, **kwargs):\n",
    "        start, name = time.time(), func.__name__\n",
    "        try:\n",
    "            res = func(*args, **kwargs)\n",
    "            tool_tracker.track_tool_call(name, {\"args\": args, \"kwargs\": kwargs},\n",
    "                                         start, time.time(), True,\n",
    "                                         str(res)[:120])\n",
    "            return res\n",
    "        except Exception as e:\n",
    "            tool_tracker.track_tool_call(name, {\"args\": args, \"kwargs\": kwargs},\n",
    "                                         start, time.time(), False, error=str(e))\n",
    "            raise\n",
    "    return wrapper\n",
    "\n",
    "# ---------- OUTILS LangChain -------------------------------------------------\n",
    "@tool\n",
    "@tracked_tool\n",
    "def search_documents(query: str, top_results: int = 3) -> str:\n",
    "    \"\"\"Recherche vectorielle dans l’index Azure Cognitive Search 'documents'.\n",
    "      Args:\n",
    "          query: la requête texte de l’utilisateur.\n",
    "          top_results: nombre de résultats max à retourner.\n",
    "      Returns:\n",
    "          Aperçu markdown des résultats ou message d’erreur.\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        client = SearchClient(config[\"search_endpoint\"], \"documents\",\n",
    "                              AzureKeyCredential(config[\"search_key\"]))\n",
    "        vec = _get_embedder().encode(query).tolist()\n",
    "        if VectorizedQuery:\n",
    "            vq = VectorizedQuery(vector=vec, k=top_results, fields=\"embedding\")\n",
    "            results = client.search(search_text=\"*\", vector_queries=[vq])\n",
    "        else:\n",
    "            from azure.search.documents.models import Vector\n",
    "            results = client.search(search_text=\"*\",\n",
    "                                    vector=Vector(value=vec, k=top_results,\n",
    "                                                  fields=\"embedding\"))\n",
    "        out = []\n",
    "        for i, r in enumerate(results, 1):\n",
    "            out.append(f\"**{i}. {r.get('filename','?')}** – \" +\n",
    "                       (r.get('content','')[:150].replace('\\n',' ') + '…'))\n",
    "        return \"\\n\".join(out) or \"Aucun résultat.\"\n",
    "    except Exception as e:\n",
    "        return f\"Erreur : {e}\"\n",
    "\n",
    "@tool\n",
    "@tracked_tool\n",
    "def explore_database_schema(table_name: str = None) -> str:\n",
    "    \"\"\"Explore la structure de la base SQL VéloCorp.\"\"\"\n",
    "    try:\n",
    "        conn_str = (\n",
    "            f\"DRIVER={{ODBC Driver 18 for SQL Server}};\"\n",
    "            f\"SERVER={config['sql_server']};DATABASE={config['sql_database']};\"\n",
    "            f\"UID={config['sql_username']};PWD={config['sql_password']};\"\n",
    "            \"Encrypt=yes;TrustServerCertificate=no;Connection Timeout=30;\"\n",
    "        )\n",
    "        with pyodbc.connect(conn_str) as conn:\n",
    "            cur = conn.cursor()\n",
    "            if not table_name:\n",
    "                cur.execute(\"SELECT TABLE_NAME FROM INFORMATION_SCHEMA.TABLES \"\n",
    "                            \"WHERE TABLE_TYPE='BASE TABLE' ORDER BY 1\")\n",
    "                return \"\\n\".join(\"- \" + r[0] for r in cur.fetchall())\n",
    "            cur.execute(\"SELECT COLUMN_NAME, DATA_TYPE FROM INFORMATION_SCHEMA.COLUMNS \"\n",
    "                        \"WHERE TABLE_NAME=?\", table_name)\n",
    "            cols = cur.fetchall()\n",
    "            return f\"**{table_name}**\\n\" + \"\\n\".join(f\"- {c[0]} ({c[1]})\" for c in cols)\n",
    "    except Exception as e:\n",
    "        return f\"Erreur schéma : {e}\"\n",
    "\n",
    "@tool\n",
    "@tracked_tool\n",
    "def query_database(sql_query: str) -> str:\n",
    "    if not sql_query.strip().upper().startswith(\"SELECT\"):\n",
    "        \"\"\"Exécute une requête SELECT sur la base VéloCorp et renvoie un tableau markdown.\"\"\"\n",
    "        return \"Seules les requêtes SELECT sont autorisées.\"\n",
    "    try:\n",
    "        conn_str = (\n",
    "            f\"DRIVER={{ODBC Driver 18 for SQL Server}};\"\n",
    "            f\"SERVER={config['sql_server']};DATABASE={config['sql_database']};\"\n",
    "            f\"UID={config['sql_username']};PWD={config['sql_password']};\"\n",
    "            \"Encrypt=yes;TrustServerCertificate=no;Connection Timeout=30;\"\n",
    "        )\n",
    "        with pyodbc.connect(conn_str) as conn:\n",
    "            cur = conn.cursor()\n",
    "            cur.execute(sql_query)\n",
    "            cols = [d[0] for d in cur.description]\n",
    "            rows = cur.fetchmany(20)\n",
    "            header = \" | \".join(cols)\n",
    "            sep = \"-\" * len(header)\n",
    "            lines = [\"```\\n\" + header, sep]\n",
    "            for r in rows:\n",
    "                lines.append(\" | \".join(str(x) for x in r))\n",
    "            lines.append(\"```\")\n",
    "            return \"\\n\".join(lines)\n",
    "    except Exception as e:\n",
    "        return f\"Erreur SQL : {e}\"\n",
    "\n",
    "@tool\n",
    "@tracked_tool\n",
    "def query_crm_api(endpoint: str, params: dict = None) -> str:\n",
    "    try:\n",
    "        r = requests.get(f\"{config['api_base_url']}/crm/{endpoint}\",\n",
    "                         params=params or {}, timeout=30)\n",
    "        r.raise_for_status()\n",
    "        return json.dumps(r.json()[:3], indent=2)[:500]\n",
    "    except Exception as e:\n",
    "        return f\"Erreur API : {e}\"\n",
    "\n",
    "tools = [search_documents, explore_database_schema,\n",
    "         query_database, query_crm_api]\n",
    "\n",
    "# ---------- AGENT LangGraph --------------------------------------------------\n",
    "llm = AzureChatOpenAI(\n",
    "    azure_endpoint  = config[\"openai_endpoint\"],\n",
    "    api_key         = config[\"openai_key\"],\n",
    "    deployment_name = config[\"chat_deployment\"],\n",
    "    api_version     = config[\"openai_version\"],\n",
    ")\n",
    "\n",
    "llm_tools = llm.bind_tools(tools)\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "def agent_node(state: AgentState):\n",
    "    system_prompt = \"\"\"\n",
    "Tu es l’assistant VéloCorp. Utilise les outils si nécessaire.\n",
    "Réponds de façon concise. Si besoin de SQL : commence par explore_database_schema().\n",
    "\"\"\"\n",
    "    msgs = [HumanMessage(content=system_prompt)] + state[\"messages\"]\n",
    "    resp = llm_tools.invoke(msgs)\n",
    "    return {\"messages\": state[\"messages\"] + [resp]}\n",
    "\n",
    "def should_continue(state: AgentState):\n",
    "    last = state[\"messages\"][-1]\n",
    "    if hasattr(last, \"tool_calls\") and last.tool_calls:\n",
    "        return \"tools\"\n",
    "    return END\n",
    "\n",
    "graph = StateGraph(AgentState)\n",
    "graph.add_node(\"agent\", agent_node)\n",
    "graph.add_node(\"tools\", ToolNode(tools))\n",
    "graph.set_entry_point(\"agent\")\n",
    "graph.add_conditional_edges(\"agent\", should_continue,\n",
    "                            {\"tools\": \"tools\", END: END})\n",
    "graph.add_edge(\"tools\", \"agent\")\n",
    "app_graph = graph.compile()\n",
    "\n",
    "def ask_agent(question: str) -> str:\n",
    "    tool_tracker.reset()\n",
    "    out = app_graph.invoke({\"messages\": [HumanMessage(content=question)]})\n",
    "    return out[\"messages\"][-1].content\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qnc0jFas48Ck"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
